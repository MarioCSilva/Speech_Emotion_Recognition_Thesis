{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBKdo1yXoJAD",
        "outputId": "bf5f3b5d-3dfa-47ec-8035-9f5498542080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Audio_Sentiment_Analysis/iemocap/data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/Audio_Sentiment_Analysis/iemocap/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "843rNBLvkSJi",
        "outputId": "3d3bb965-f410-41dc-dcae-f8873f46a019"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "# go to upper diretory\n",
        "sys.path.append(os.path.abspath('./../../../'))\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from sklearn.ensemble import RandomForestClassifier as RandomForest, HistGradientBoostingClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
        "from Audio_Sentiment_Analysis.utils.Configuration import Configuration\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "AUDIO_DIR = f\"{os.path.abspath('./../../../')}/IEMOCAP_Dataset\"\n",
        "EXTRACTED_FEATURES_FILE = f\"{os.path.abspath('./../../../')}/Audio_Sentiment_Analysis/iemocap/data/extracted_features_iemocap.csv\"\n",
        "CONFIG_FILE = f\"{os.path.abspath('./../../../')}/Audio_Sentiment_Analysis/iemocap/config.json\"\n",
        "RAW_AUDIO_FILES = f\"{os.path.abspath('./../../../')}/Audio_Sentiment_Analysis/iemocap/data/raw_audio_files.csv\"\n",
        "\n",
        "config = Configuration.load_json(CONFIG_FILE)\n",
        "# !pip install autokeras\n",
        "# !pip install --upgrade scipy==1.7.0\n",
        "# !pip install auto-sklearn\n",
        "import autokeras as ak\n",
        "# from autosklearn.classification import AutoSklearnClassifier\n",
        "# from autosklearn.regression import AutoSklearnRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSg2cYuckSJo"
      },
      "source": [
        "## Read the extracted features from the CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "WLl1X99mkSJp",
        "outputId": "34bd4adb-cb22-4a94-f205-20fbae028fdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Audio Files: 10039\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Interaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion_Id</th>\n",
              "      <th>Valence</th>\n",
              "      <th>Activation</th>\n",
              "      <th>Dominance</th>\n",
              "      <th>std_chroma_stft</th>\n",
              "      <th>mean_zcr</th>\n",
              "      <th>...</th>\n",
              "      <th>max_mfcc6</th>\n",
              "      <th>min_mfcc7</th>\n",
              "      <th>var_mfcc9</th>\n",
              "      <th>max_mfcc9</th>\n",
              "      <th>max_mfcc10</th>\n",
              "      <th>max_mfcc13</th>\n",
              "      <th>var_mfcc14</th>\n",
              "      <th>var_mfcc15</th>\n",
              "      <th>min_mfcc17</th>\n",
              "      <th>min_mfcc19</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>File</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ses01F_impro01_F012</th>\n",
              "      <td>improvised</td>\n",
              "      <td>Female</td>\n",
              "      <td>2.750</td>\n",
              "      <td>angry</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.296270</td>\n",
              "      <td>0.082856</td>\n",
              "      <td>...</td>\n",
              "      <td>39.327560</td>\n",
              "      <td>-40.651329</td>\n",
              "      <td>42.375973</td>\n",
              "      <td>19.492970</td>\n",
              "      <td>19.512123</td>\n",
              "      <td>18.821735</td>\n",
              "      <td>47.666279</td>\n",
              "      <td>51.472340</td>\n",
              "      <td>-18.892769</td>\n",
              "      <td>-27.943581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses01F_impro04_F028</th>\n",
              "      <td>improvised</td>\n",
              "      <td>Female</td>\n",
              "      <td>2.010</td>\n",
              "      <td>angry</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.319851</td>\n",
              "      <td>0.086560</td>\n",
              "      <td>...</td>\n",
              "      <td>62.818893</td>\n",
              "      <td>-40.228039</td>\n",
              "      <td>84.092949</td>\n",
              "      <td>24.274593</td>\n",
              "      <td>11.059961</td>\n",
              "      <td>36.497154</td>\n",
              "      <td>29.247034</td>\n",
              "      <td>61.287384</td>\n",
              "      <td>-17.456673</td>\n",
              "      <td>-15.254041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses01F_impro04_F029</th>\n",
              "      <td>improvised</td>\n",
              "      <td>Female</td>\n",
              "      <td>3.160</td>\n",
              "      <td>angry</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.298296</td>\n",
              "      <td>0.085880</td>\n",
              "      <td>...</td>\n",
              "      <td>29.858166</td>\n",
              "      <td>-33.455795</td>\n",
              "      <td>164.847565</td>\n",
              "      <td>34.833263</td>\n",
              "      <td>22.882631</td>\n",
              "      <td>33.635147</td>\n",
              "      <td>118.356186</td>\n",
              "      <td>128.460770</td>\n",
              "      <td>-32.842518</td>\n",
              "      <td>-12.516586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses01F_impro04_F030</th>\n",
              "      <td>improvised</td>\n",
              "      <td>Female</td>\n",
              "      <td>3.185</td>\n",
              "      <td>angry</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.316109</td>\n",
              "      <td>0.106300</td>\n",
              "      <td>...</td>\n",
              "      <td>48.537384</td>\n",
              "      <td>-38.774422</td>\n",
              "      <td>178.178299</td>\n",
              "      <td>24.138340</td>\n",
              "      <td>11.319570</td>\n",
              "      <td>35.046803</td>\n",
              "      <td>183.465393</td>\n",
              "      <td>119.128494</td>\n",
              "      <td>-13.127378</td>\n",
              "      <td>-24.713459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses01F_impro04_F031</th>\n",
              "      <td>improvised</td>\n",
              "      <td>Female</td>\n",
              "      <td>4.400</td>\n",
              "      <td>angry</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.314387</td>\n",
              "      <td>0.065918</td>\n",
              "      <td>...</td>\n",
              "      <td>44.125771</td>\n",
              "      <td>-49.090309</td>\n",
              "      <td>100.364433</td>\n",
              "      <td>35.686844</td>\n",
              "      <td>29.594337</td>\n",
              "      <td>11.990172</td>\n",
              "      <td>68.253944</td>\n",
              "      <td>51.992161</td>\n",
              "      <td>-20.573139</td>\n",
              "      <td>-20.019981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses05M_script03_2_M013</th>\n",
              "      <td>scripted</td>\n",
              "      <td>Male</td>\n",
              "      <td>9.340</td>\n",
              "      <td>other</td>\n",
              "      <td>10</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.314951</td>\n",
              "      <td>0.063627</td>\n",
              "      <td>...</td>\n",
              "      <td>58.600712</td>\n",
              "      <td>-46.007534</td>\n",
              "      <td>113.818436</td>\n",
              "      <td>32.636822</td>\n",
              "      <td>28.463696</td>\n",
              "      <td>25.335880</td>\n",
              "      <td>78.160225</td>\n",
              "      <td>66.925186</td>\n",
              "      <td>-27.014687</td>\n",
              "      <td>-21.044426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses05M_script03_2_M014</th>\n",
              "      <td>scripted</td>\n",
              "      <td>Male</td>\n",
              "      <td>4.150</td>\n",
              "      <td>other</td>\n",
              "      <td>10</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.315053</td>\n",
              "      <td>0.067145</td>\n",
              "      <td>...</td>\n",
              "      <td>73.493271</td>\n",
              "      <td>-54.896301</td>\n",
              "      <td>162.575638</td>\n",
              "      <td>31.630028</td>\n",
              "      <td>12.225033</td>\n",
              "      <td>33.560890</td>\n",
              "      <td>87.977707</td>\n",
              "      <td>42.288971</td>\n",
              "      <td>-24.003210</td>\n",
              "      <td>-19.897762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses05M_script03_2_M018</th>\n",
              "      <td>scripted</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.170</td>\n",
              "      <td>other</td>\n",
              "      <td>10</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.302163</td>\n",
              "      <td>0.062219</td>\n",
              "      <td>...</td>\n",
              "      <td>51.708046</td>\n",
              "      <td>-34.321487</td>\n",
              "      <td>181.688660</td>\n",
              "      <td>23.869041</td>\n",
              "      <td>14.644627</td>\n",
              "      <td>14.957552</td>\n",
              "      <td>41.870499</td>\n",
              "      <td>43.103497</td>\n",
              "      <td>-20.033688</td>\n",
              "      <td>-19.955128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses05M_script03_2_M019</th>\n",
              "      <td>scripted</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.180</td>\n",
              "      <td>other</td>\n",
              "      <td>10</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.310805</td>\n",
              "      <td>0.116048</td>\n",
              "      <td>...</td>\n",
              "      <td>58.984211</td>\n",
              "      <td>-54.916523</td>\n",
              "      <td>73.387558</td>\n",
              "      <td>23.126339</td>\n",
              "      <td>13.553119</td>\n",
              "      <td>24.739117</td>\n",
              "      <td>51.918839</td>\n",
              "      <td>60.310535</td>\n",
              "      <td>-22.075874</td>\n",
              "      <td>-19.231363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ses05M_script03_2_M021</th>\n",
              "      <td>scripted</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.400</td>\n",
              "      <td>other</td>\n",
              "      <td>10</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.320674</td>\n",
              "      <td>0.120333</td>\n",
              "      <td>...</td>\n",
              "      <td>68.866486</td>\n",
              "      <td>-47.562469</td>\n",
              "      <td>194.224579</td>\n",
              "      <td>23.398148</td>\n",
              "      <td>23.116982</td>\n",
              "      <td>20.446377</td>\n",
              "      <td>71.395477</td>\n",
              "      <td>28.724272</td>\n",
              "      <td>-28.672276</td>\n",
              "      <td>-21.132488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10039 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Interaction  Gender  Duration Emotion  Emotion_Id  \\\n",
              "File                                                                       \n",
              "Ses01F_impro01_F012     improvised  Female     2.750   angry           0   \n",
              "Ses01F_impro04_F028     improvised  Female     2.010   angry           0   \n",
              "Ses01F_impro04_F029     improvised  Female     3.160   angry           0   \n",
              "Ses01F_impro04_F030     improvised  Female     3.185   angry           0   \n",
              "Ses01F_impro04_F031     improvised  Female     4.400   angry           0   \n",
              "...                            ...     ...       ...     ...         ...   \n",
              "Ses05M_script03_2_M013    scripted    Male     9.340   other          10   \n",
              "Ses05M_script03_2_M014    scripted    Male     4.150   other          10   \n",
              "Ses05M_script03_2_M018    scripted    Male     2.170   other          10   \n",
              "Ses05M_script03_2_M019    scripted    Male     1.180   other          10   \n",
              "Ses05M_script03_2_M021    scripted    Male     2.400   other          10   \n",
              "\n",
              "                        Valence  Activation  Dominance  std_chroma_stft  \\\n",
              "File                                                                      \n",
              "Ses01F_impro01_F012         2.0         3.5        3.5         0.296270   \n",
              "Ses01F_impro04_F028         2.0         3.5        3.5         0.319851   \n",
              "Ses01F_impro04_F029         1.5         4.0        4.0         0.298296   \n",
              "Ses01F_impro04_F030         1.5         3.5        4.0         0.316109   \n",
              "Ses01F_impro04_F031         1.5         3.0        3.5         0.314387   \n",
              "...                         ...         ...        ...              ...   \n",
              "Ses05M_script03_2_M013      2.0         3.5        4.0         0.314951   \n",
              "Ses05M_script03_2_M014      1.5         3.5        4.0         0.315053   \n",
              "Ses05M_script03_2_M018      3.5         3.0        3.0         0.302163   \n",
              "Ses05M_script03_2_M019      2.5         3.0        3.5         0.310805   \n",
              "Ses05M_script03_2_M021      2.0         3.5        4.0         0.320674   \n",
              "\n",
              "                        mean_zcr  ...  max_mfcc6  min_mfcc7   var_mfcc9  \\\n",
              "File                              ...                                     \n",
              "Ses01F_impro01_F012     0.082856  ...  39.327560 -40.651329   42.375973   \n",
              "Ses01F_impro04_F028     0.086560  ...  62.818893 -40.228039   84.092949   \n",
              "Ses01F_impro04_F029     0.085880  ...  29.858166 -33.455795  164.847565   \n",
              "Ses01F_impro04_F030     0.106300  ...  48.537384 -38.774422  178.178299   \n",
              "Ses01F_impro04_F031     0.065918  ...  44.125771 -49.090309  100.364433   \n",
              "...                          ...  ...        ...        ...         ...   \n",
              "Ses05M_script03_2_M013  0.063627  ...  58.600712 -46.007534  113.818436   \n",
              "Ses05M_script03_2_M014  0.067145  ...  73.493271 -54.896301  162.575638   \n",
              "Ses05M_script03_2_M018  0.062219  ...  51.708046 -34.321487  181.688660   \n",
              "Ses05M_script03_2_M019  0.116048  ...  58.984211 -54.916523   73.387558   \n",
              "Ses05M_script03_2_M021  0.120333  ...  68.866486 -47.562469  194.224579   \n",
              "\n",
              "                        max_mfcc9  max_mfcc10  max_mfcc13  var_mfcc14  \\\n",
              "File                                                                    \n",
              "Ses01F_impro01_F012     19.492970   19.512123   18.821735   47.666279   \n",
              "Ses01F_impro04_F028     24.274593   11.059961   36.497154   29.247034   \n",
              "Ses01F_impro04_F029     34.833263   22.882631   33.635147  118.356186   \n",
              "Ses01F_impro04_F030     24.138340   11.319570   35.046803  183.465393   \n",
              "Ses01F_impro04_F031     35.686844   29.594337   11.990172   68.253944   \n",
              "...                           ...         ...         ...         ...   \n",
              "Ses05M_script03_2_M013  32.636822   28.463696   25.335880   78.160225   \n",
              "Ses05M_script03_2_M014  31.630028   12.225033   33.560890   87.977707   \n",
              "Ses05M_script03_2_M018  23.869041   14.644627   14.957552   41.870499   \n",
              "Ses05M_script03_2_M019  23.126339   13.553119   24.739117   51.918839   \n",
              "Ses05M_script03_2_M021  23.398148   23.116982   20.446377   71.395477   \n",
              "\n",
              "                        var_mfcc15  min_mfcc17  min_mfcc19  \n",
              "File                                                        \n",
              "Ses01F_impro01_F012      51.472340  -18.892769  -27.943581  \n",
              "Ses01F_impro04_F028      61.287384  -17.456673  -15.254041  \n",
              "Ses01F_impro04_F029     128.460770  -32.842518  -12.516586  \n",
              "Ses01F_impro04_F030     119.128494  -13.127378  -24.713459  \n",
              "Ses01F_impro04_F031      51.992161  -20.573139  -20.019981  \n",
              "...                            ...         ...         ...  \n",
              "Ses05M_script03_2_M013   66.925186  -27.014687  -21.044426  \n",
              "Ses05M_script03_2_M014   42.288971  -24.003210  -19.897762  \n",
              "Ses05M_script03_2_M018   43.103497  -20.033688  -19.955128  \n",
              "Ses05M_script03_2_M019   60.310535  -22.075874  -19.231363  \n",
              "Ses05M_script03_2_M021   28.724272  -28.672276  -21.132488  \n",
              "\n",
              "[10039 rows x 32 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(EXTRACTED_FEATURES_FILE)\n",
        "print(f\"Number of Audio Files: {df.shape[0]}\")\n",
        "df = df.sort_values(['Emotion_Id', 'Gender'], ascending = (True, True))\n",
        "df = df.set_index('File')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJvGhP-xkSJr"
      },
      "source": [
        "## Data used in SOA models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion_Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <th>0</th>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <th>1</th>\n",
              "      <td>1636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <th>3</th>\n",
              "      <td>1708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <th>2</th>\n",
              "      <td>1084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Emotion\n",
              "                     count\n",
              "Emotion Emotion_Id        \n",
              "angry   0             1103\n",
              "happy   1             1636\n",
              "neutral 3             1708\n",
              "sad     2             1084"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df['Emotion'].isin({'angry', 'neutral', 'sad', 'happy', 'excited'})]\n",
        "df.loc[df['Emotion'] == 'excited', 'Emotion'] = 'happy'\n",
        "df.loc[df['Emotion_Id'] == 5, 'Emotion_Id'] = 1\n",
        "data = df.iloc[:,8:]\n",
        "categorical_labels = np.ravel(df.iloc[:,4:5].values)\n",
        "df.groupby(['Emotion', 'Emotion_Id']).agg({'Emotion': ['count']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Categorical Problem (anger, happiness (+ excited), neutral, sadness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbM2lOxSkSJx"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moWPBD1PkSJy"
      },
      "source": [
        "### Simple Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_cm_predictions(model, input_data, labels, cv=5, draw_corr_matrix=True, verbose=1, n_jobs=8):\n",
        "    y_pred = cross_val_predict(model, input_data, labels, cv=cv, verbose=verbose, n_jobs=n_jobs)\n",
        "\n",
        "    print(\"accuracy: \", metrics.accuracy_score(labels, y_pred))\n",
        "    print(\"f1 score macro: \", metrics.f1_score(labels, y_pred, average='macro') )\n",
        "    print(\"f1 score micro: \", metrics.f1_score(labels, y_pred, average='micro') )\n",
        "    print(\"precision score: \", metrics.precision_score(labels, y_pred, average='macro') )\n",
        "    print(\"recall score: \", metrics.recall_score(labels, y_pred, average='macro') )\n",
        "    print(\"hamming loss: \", metrics.hamming_loss(labels, y_pred))\n",
        "    print(\"matthews corrcoef: \", metrics.matthews_corrcoef(labels, y_pred) )\n",
        "    print(\"zero one loss: \", metrics.zero_one_loss(labels, y_pred))\n",
        "    print(\"mean absolute error: \", metrics.mean_absolute_error(labels, y_pred))\n",
        "\n",
        "    print(metrics.classification_report(labels, y_pred))\n",
        "\n",
        "    if draw_corr_matrix:\n",
        "        cm = metrics.confusion_matrix(labels, y_pred)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "        plt.title(\"Confusion Matrix Predicted Labels\")\n",
        "        plt.xlabel(\"Emotions Labels\")\n",
        "        plt.ylabel(\"Emotions Labels\")\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjIxNUmRkSJy",
        "outputId": "4d9e4de0-e015-41e8-ae3e-b2540440e7cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   30.1s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.4952088229976496\n",
            "f1 score macro:  0.5128402898669654\n",
            "f1 score micro:  0.4952088229976496\n",
            "precision score:  0.5235160408175284\n",
            "recall score:  0.5050289689027115\n",
            "hamming loss:  0.5047911770023504\n",
            "matthews corrcoef:  0.31341736401352394\n",
            "zero one loss:  0.5047911770023503\n",
            "mean absolute error:  0.7868378231784487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.54      0.58      1103\n",
            "           1       0.41      0.45      0.42      1636\n",
            "           2       0.60      0.57      0.58      1084\n",
            "           3       0.45      0.47      0.46      1708\n",
            "\n",
            "    accuracy                           0.50      5531\n",
            "   macro avg       0.52      0.51      0.51      5531\n",
            "weighted avg       0.50      0.50      0.50      5531\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_cm_predictions(RandomForest(random_state=1, max_features=None), data.values, categorical_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmT0Juq9865F"
      },
      "source": [
        "### AutoSKlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiopTMmV8-r_",
        "outputId": "102de3ec-2f29-4ffb-d464-1b292ad43138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AutoSklearnClassifier(max_models_on_disc=None, n_jobs=-1,\n",
              "                      per_run_time_limit=720, resampling_strategy='cv',\n",
              "                      resampling_strategy_arguments={'cv': {'folds': 5},\n",
              "                                                     'folds': 5})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoSklearnClassifier(\n",
        "    max_models_on_disc=None,\n",
        "    resampling_strategy='cv',\n",
        "    resampling_strategy_arguments={'cv': {'folds': 5}},\n",
        "    seed=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(data.values, categorical_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvWHu2_SPWE",
        "outputId": "43c9d8a6-f80c-4019-adac-ba30c0a2d30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auto-sklearn results:\n",
            "  Dataset name: af569de4-f17d-11ec-8351-0242ac1c0002\n",
            "  Metric: accuracy\n",
            "  Best validation score: 0.606400\n",
            "  Number of target algorithm runs: 39\n",
            "  Number of successful target algorithm runs: 31\n",
            "  Number of crashed target algorithm runs: 1\n",
            "  Number of target algorithms that exceeded the time limit: 6\n",
            "  Number of target algorithms that exceeded the memory limit: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.sprint_statistics())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9hGra1zDqC9",
        "outputId": "9520ae2d-1fb7-4c2a-8fa6-30ae1ef0c5fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{2: {'cost': 0.3957693003073585,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20de5b2550>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20e7116a90>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20de5b2750>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc394b90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc384310>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc394ad0>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbf15b50>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbf852d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbf15a90>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbd38a50>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbd2e590>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbd38990>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db9a9850>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dba14fd0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db9a9790>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)}],\n",
              "  'model_id': 2,\n",
              "  'rank': 2,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 5: {'cost': 0.4077020430301935,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc247810>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20daeb32d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc247550>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=5.027708640006448e-08,\n",
              "                                   learning_rate=0.09750328007832798, max_iter=32,\n",
              "                                   max_leaf_nodes=1234, min_samples_leaf=25,\n",
              "                                   n_iter_no_change=1, random_state=1,\n",
              "                                   validation_fraction=0.08300813783286698,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc1d6bd0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc3dc550>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc1d6910>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=5.027708640006448e-08,\n",
              "                                   learning_rate=0.09750328007832798, max_iter=32,\n",
              "                                   max_leaf_nodes=1234, min_samples_leaf=25,\n",
              "                                   n_iter_no_change=1, random_state=1,\n",
              "                                   validation_fraction=0.08300813783286698,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbfcd2d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbf43a90>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbfcd250>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=5.027708640006448e-08,\n",
              "                                   learning_rate=0.09750328007832798, max_iter=32,\n",
              "                                   max_leaf_nodes=1234, min_samples_leaf=25,\n",
              "                                   n_iter_no_change=1, random_state=1,\n",
              "                                   validation_fraction=0.08300813783286698,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbeae810>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc314790>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbeae690>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=5.027708640006448e-08,\n",
              "                                   learning_rate=0.09750328007832798, max_iter=32,\n",
              "                                   max_leaf_nodes=1234, min_samples_leaf=25,\n",
              "                                   n_iter_no_change=1, random_state=1,\n",
              "                                   validation_fraction=0.08300813783286698,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbea0550>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20e6cf5a10>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbea02d0>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=5.027708640006448e-08,\n",
              "                                   learning_rate=0.09750328007832798, max_iter=32,\n",
              "                                   max_leaf_nodes=1234, min_samples_leaf=25,\n",
              "                                   n_iter_no_change=1, random_state=1,\n",
              "                                   validation_fraction=0.08300813783286698,\n",
              "                                   warm_start=True)}],\n",
              "  'model_id': 5,\n",
              "  'rank': 5,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 8: {'cost': 0.4838184776713072,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbd423d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbdeb910>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbcb9a10>,\n",
              "    'sklearn_classifier': PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
              "                                max_iter=128, random_state=1,\n",
              "                                tol=4.631073253805713e-05, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbe85550>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d73c3b50>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbf3eb90>,\n",
              "    'sklearn_classifier': PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
              "                                max_iter=128, random_state=1,\n",
              "                                tol=4.631073253805713e-05, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db9e2390>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db8e6c10>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db91a750>,\n",
              "    'sklearn_classifier': PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
              "                                max_iter=64, random_state=1,\n",
              "                                tol=4.631073253805713e-05, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db8246d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db88b350>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db824b10>,\n",
              "    'sklearn_classifier': PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
              "                                max_iter=128, random_state=1,\n",
              "                                tol=4.631073253805713e-05, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db80f610>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db7f1ad0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db80f250>,\n",
              "    'sklearn_classifier': PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
              "                                max_iter=64, random_state=1,\n",
              "                                tol=4.631073253805713e-05, warm_start=True)}],\n",
              "  'model_id': 8,\n",
              "  'rank': 9,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 16: {'cost': 0.41511480744892426,\n",
              "  'ensemble_weight': 0.04,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbe482d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dae33dd0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbe15a90>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=6, min_samples_split=6, n_estimators=512,\n",
              "                           n_jobs=1, random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db916790>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbe85e50>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db916390>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=5, min_samples_split=6, n_estimators=512,\n",
              "                           n_jobs=1, random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db3e9510>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db44ff90>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db3e3f90>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, min_samples_split=6, n_estimators=512,\n",
              "                           n_jobs=1, random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dafaa1d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db00f210>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dafa4ad0>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=4, min_samples_split=6, n_estimators=512,\n",
              "                           n_jobs=1, random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20d7f02150>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d7eee490>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d7efdbd0>,\n",
              "    'sklearn_classifier': RandomForestClassifier(max_features=5, min_samples_split=6, n_estimators=512,\n",
              "                           n_jobs=1, random_state=1, warm_start=True)}],\n",
              "  'model_id': 16,\n",
              "  'rank': 7,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 17: {'cost': 0.4020972699331043,\n",
              "  'ensemble_weight': 0.08,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dade6950>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20daea9e10>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dae47dd0>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.018821286956948503)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc44d290>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc3e8c10>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc3ec090>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.018821286956948503)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc329d90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc38a3d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc329d50>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.018821286956948503)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc2e4110>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc3ae690>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc3d7fd0>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.018821286956948503)},\n",
              "   {'balancing': Balancing(random_state=1),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc218ed0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc285510>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc218b90>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.018821286956948503)}],\n",
              "  'model_id': 17,\n",
              "  'rank': 4,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 19: {'cost': 0.39974688121497015,\n",
              "  'ensemble_weight': 0.04,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dae6ced0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20daeaded0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20daec8f50>,\n",
              "    'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=5, min_samples_leaf=2,\n",
              "                           min_samples_split=3, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc25be90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc2e1710>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dc25ba50>,\n",
              "    'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=5, min_samples_leaf=2,\n",
              "                           min_samples_split=3, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbe48a90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbe53690>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbe48690>,\n",
              "    'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=5, min_samples_leaf=2,\n",
              "                           min_samples_split=3, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dba42b10>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dba2d790>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dba42790>,\n",
              "    'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=5, min_samples_leaf=2,\n",
              "                           min_samples_split=3, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db559510>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db5c57d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db559110>,\n",
              "    'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=5, min_samples_leaf=2,\n",
              "                           min_samples_split=3, n_estimators=512, n_jobs=1,\n",
              "                           random_state=1, warm_start=True)}],\n",
              "  'model_id': 19,\n",
              "  'rank': 3,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 23: {'cost': 0.6257457964201771,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db762090>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d73a3b90>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db9aec10>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.00010000000000000009)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db520550>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db4f8a10>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db520250>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.00010000000000000009)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db496c10>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db4a2ad0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db4968d0>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.00010000000000000009)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db4927d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db47dbd0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db4923d0>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.00010000000000000009)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db3972d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db3fe3d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db397050>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
              "                               tol=0.00010000000000000009)}],\n",
              "  'model_id': 23,\n",
              "  'rank': 10,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 24: {'cost': 0.3935997107213885,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20e77b8110>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20e181e350>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20e77b8f90>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=2.506856350040198e-06,\n",
              "                                   learning_rate=0.04634380160611007, max_iter=512,\n",
              "                                   max_leaf_nodes=11, min_samples_leaf=41,\n",
              "                                   n_iter_no_change=17, random_state=1,\n",
              "                                   validation_fraction=None, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbfb1ed0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc0062d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbfb1e50>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=2.506856350040198e-06,\n",
              "                                   learning_rate=0.04634380160611007, max_iter=512,\n",
              "                                   max_leaf_nodes=11, min_samples_leaf=41,\n",
              "                                   n_iter_no_change=17, random_state=1,\n",
              "                                   validation_fraction=None, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbb09250>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbb34650>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbb091d0>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=2.506856350040198e-06,\n",
              "                                   learning_rate=0.04634380160611007, max_iter=512,\n",
              "                                   max_leaf_nodes=11, min_samples_leaf=41,\n",
              "                                   n_iter_no_change=17, random_state=1,\n",
              "                                   validation_fraction=None, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db646590>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db675990>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db646510>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=2.506856350040198e-06,\n",
              "                                   learning_rate=0.04634380160611007, max_iter=512,\n",
              "                                   max_leaf_nodes=11, min_samples_leaf=41,\n",
              "                                   n_iter_no_change=17, random_state=1,\n",
              "                                   validation_fraction=None, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db1858d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db1b6cd0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db185850>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
              "                                   l2_regularization=2.506856350040198e-06,\n",
              "                                   learning_rate=0.04634380160611007, max_iter=512,\n",
              "                                   max_leaf_nodes=11, min_samples_leaf=41,\n",
              "                                   n_iter_no_change=17, random_state=1,\n",
              "                                   validation_fraction=None, warm_start=True)}],\n",
              "  'model_id': 24,\n",
              "  'rank': 1,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 25: {'cost': 0.41457241005243173,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbdb3d10>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc3e88d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbdb3390>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
              "                                   l2_regularization=2.188553300996835e-10,\n",
              "                                   learning_rate=0.06138190336151616, max_iter=512,\n",
              "                                   max_leaf_nodes=20, n_iter_no_change=0,\n",
              "                                   random_state=1, validation_fraction=None,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db592e50>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db51c950>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db592a90>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
              "                                   l2_regularization=2.188553300996835e-10,\n",
              "                                   learning_rate=0.06138190336151616, max_iter=512,\n",
              "                                   max_leaf_nodes=20, n_iter_no_change=0,\n",
              "                                   random_state=1, validation_fraction=None,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20d7fcc390>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d807d5d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d7fcc110>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
              "                                   l2_regularization=2.188553300996835e-10,\n",
              "                                   learning_rate=0.06138190336151616, max_iter=512,\n",
              "                                   max_leaf_nodes=20, n_iter_no_change=0,\n",
              "                                   random_state=1, validation_fraction=None,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20d7b63550>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d7b9a750>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d7b632d0>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
              "                                   l2_regularization=2.188553300996835e-10,\n",
              "                                   learning_rate=0.06138190336151616, max_iter=512,\n",
              "                                   max_leaf_nodes=20, n_iter_no_change=0,\n",
              "                                   random_state=1, validation_fraction=None,\n",
              "                                   warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20d76fa750>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d7731950>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d76fa4d0>,\n",
              "    'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
              "                                   l2_regularization=2.188553300996835e-10,\n",
              "                                   learning_rate=0.06138190336151616, max_iter=512,\n",
              "                                   max_leaf_nodes=20, n_iter_no_change=0,\n",
              "                                   random_state=1, validation_fraction=None,\n",
              "                                   warm_start=True)}],\n",
              "  'model_id': 25,\n",
              "  'rank': 6,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 27: {'cost': 0.45308262520339904,\n",
              "  'ensemble_weight': 0.06,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20d74330d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dbed3a50>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d7428510>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3306135150299744, solver='lsqr',\n",
              "                               tol=0.0007215763283486354)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dc3ffa90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d73865d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d7390c90>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3306135150299744, solver='lsqr',\n",
              "                               tol=0.0007215763283486354)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20d7394490>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d73b39d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20d7394090>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3306135150299744, solver='lsqr',\n",
              "                               tol=0.0007215763283486354)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbc9a950>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d7367ad0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbc9a050>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3306135150299744, solver='lsqr',\n",
              "                               tol=0.0007215763283486354)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20dbc5de90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d73af750>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20dbc5d7d0>,\n",
              "    'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3306135150299744, solver='lsqr',\n",
              "                               tol=0.0007215763283486354)}],\n",
              "  'model_id': 27,\n",
              "  'rank': 8,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 28: {'cost': 0.6575664436810702,\n",
              "  'ensemble_weight': 0.02,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db392750>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20dc23cd50>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db38dfd0>,\n",
              "    'sklearn_classifier': BernoulliNB(alpha=39.87397441278958, fit_prior=False)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db54f150>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db2a2110>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db2a5e50>,\n",
              "    'sklearn_classifier': BernoulliNB(alpha=39.87397441278958, fit_prior=False)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db147950>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db137bd0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db147710>,\n",
              "    'sklearn_classifier': BernoulliNB(alpha=39.87397441278958, fit_prior=False)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db2d9150>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db105d50>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db2d9dd0>,\n",
              "    'sklearn_classifier': BernoulliNB(alpha=39.87397441278958, fit_prior=False)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db06ab10>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db0d2850>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db06a750>,\n",
              "    'sklearn_classifier': BernoulliNB(alpha=39.87397441278958, fit_prior=False)}],\n",
              "  'model_id': 28,\n",
              "  'rank': 11,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')},\n",
              " 36: {'cost': 0.691195082263605,\n",
              "  'ensemble_weight': 0.64,\n",
              "  'estimators': [{'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db038d90>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20db38df50>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db038590>,\n",
              "    'sklearn_classifier': SGDClassifier(alpha=0.005360583549766929, eta0=0.002965979312440245,\n",
              "                  learning_rate='invscaling', loss='log', max_iter=256,\n",
              "                  penalty='l1', power_t=0.6437548139668263, random_state=1,\n",
              "                  tol=0.00016790195391295395, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db16d7d0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20daf6ce10>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db3f8e10>,\n",
              "    'sklearn_classifier': SGDClassifier(alpha=0.005360583549766929, eta0=0.002965979312440245,\n",
              "                  learning_rate='invscaling', loss='log', max_iter=256,\n",
              "                  penalty='l1', power_t=0.6437548139668263, random_state=1,\n",
              "                  tol=0.00016790195391295395, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20daed8210>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20daf3d9d0>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20daf51810>,\n",
              "    'sklearn_classifier': SGDClassifier(alpha=0.005360583549766929, eta0=0.002965979312440245,\n",
              "                  learning_rate='invscaling', loss='log', max_iter=256,\n",
              "                  penalty='l1', power_t=0.6437548139668263, random_state=1,\n",
              "                  tol=0.00016790195391295395, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db2f9ad0>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20daf01450>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20daf0fc10>,\n",
              "    'sklearn_classifier': SGDClassifier(alpha=0.005360583549766929, eta0=0.002965979312440245,\n",
              "                  learning_rate='invscaling', loss='log', max_iter=256,\n",
              "                  penalty='l1', power_t=0.6437548139668263, random_state=1,\n",
              "                  tol=0.00016790195391295395, warm_start=True)},\n",
              "   {'balancing': Balancing(random_state=1, strategy='weighting'),\n",
              "    'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f20db41b510>,\n",
              "    'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f20d8134490>,\n",
              "    'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f20db41b210>,\n",
              "    'sklearn_classifier': SGDClassifier(alpha=0.005360583549766929, eta0=0.002965979312440245,\n",
              "                  learning_rate='invscaling', loss='log', max_iter=256,\n",
              "                  penalty='l1', power_t=0.6437548139668263, random_state=1,\n",
              "                  tol=0.00016790195391295395, warm_start=True)}],\n",
              "  'model_id': 36,\n",
              "  'rank': 12,\n",
              "  'voting_model': VotingClassifier(estimators=None, voting='soft')}}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "Hjs79W6US4bl",
        "outputId": "64f9d601-2b5f-4023-c767-28ce5ecccd0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-397adea6-2d4b-449d-8671-c0d7d691d8c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>ensemble_weight</th>\n",
              "      <th>type</th>\n",
              "      <th>cost</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>gradient_boosting</td>\n",
              "      <td>0.393600</td>\n",
              "      <td>62.607876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.02</td>\n",
              "      <td>random_forest</td>\n",
              "      <td>0.395769</td>\n",
              "      <td>93.652015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>0.04</td>\n",
              "      <td>random_forest</td>\n",
              "      <td>0.399747</td>\n",
              "      <td>147.364214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4</td>\n",
              "      <td>0.08</td>\n",
              "      <td>lda</td>\n",
              "      <td>0.402097</td>\n",
              "      <td>67.067775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.02</td>\n",
              "      <td>gradient_boosting</td>\n",
              "      <td>0.407702</td>\n",
              "      <td>22.090618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6</td>\n",
              "      <td>0.02</td>\n",
              "      <td>gradient_boosting</td>\n",
              "      <td>0.414572</td>\n",
              "      <td>73.311230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7</td>\n",
              "      <td>0.04</td>\n",
              "      <td>random_forest</td>\n",
              "      <td>0.415115</td>\n",
              "      <td>98.022274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>8</td>\n",
              "      <td>0.06</td>\n",
              "      <td>lda</td>\n",
              "      <td>0.453083</td>\n",
              "      <td>17.005109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.02</td>\n",
              "      <td>passive_aggressive</td>\n",
              "      <td>0.483818</td>\n",
              "      <td>7.822896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>10</td>\n",
              "      <td>0.02</td>\n",
              "      <td>lda</td>\n",
              "      <td>0.625746</td>\n",
              "      <td>9.665538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>11</td>\n",
              "      <td>0.02</td>\n",
              "      <td>bernoulli_nb</td>\n",
              "      <td>0.657566</td>\n",
              "      <td>11.982064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.691195</td>\n",
              "      <td>75.407885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-397adea6-2d4b-449d-8671-c0d7d691d8c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-397adea6-2d4b-449d-8671-c0d7d691d8c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-397adea6-2d4b-449d-8671-c0d7d691d8c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          rank  ensemble_weight                type      cost    duration\n",
              "model_id                                                                 \n",
              "24           1             0.02   gradient_boosting  0.393600   62.607876\n",
              "2            2             0.02       random_forest  0.395769   93.652015\n",
              "19           3             0.04       random_forest  0.399747  147.364214\n",
              "17           4             0.08                 lda  0.402097   67.067775\n",
              "5            5             0.02   gradient_boosting  0.407702   22.090618\n",
              "25           6             0.02   gradient_boosting  0.414572   73.311230\n",
              "16           7             0.04       random_forest  0.415115   98.022274\n",
              "27           8             0.06                 lda  0.453083   17.005109\n",
              "8            9             0.02  passive_aggressive  0.483818    7.822896\n",
              "23          10             0.02                 lda  0.625746    9.665538\n",
              "28          11             0.02        bernoulli_nb  0.657566   11.982064\n",
              "36          12             0.64                 sgd  0.691195   75.407885"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.leaderboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing the Highest Ranked Model from the Auto Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   10.2s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.4926776351473513\n",
            "f1 score macro:  0.5109447063089536\n",
            "f1 score micro:  0.4926776351473513\n",
            "precision score:  0.5225208539031851\n",
            "recall score:  0.5032333491043759\n",
            "hamming loss:  0.5073223648526487\n",
            "matthews corrcoef:  0.3107950614540945\n",
            "zero one loss:  0.5073223648526487\n",
            "mean absolute error:  0.7909962032182245\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.56      0.60      1103\n",
            "           1       0.40      0.47      0.43      1636\n",
            "           2       0.58      0.55      0.56      1084\n",
            "           3       0.46      0.44      0.45      1708\n",
            "\n",
            "    accuracy                           0.49      5531\n",
            "   macro avg       0.52      0.50      0.51      5531\n",
            "weighted avg       0.50      0.49      0.50      5531\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_cm_predictions(HistGradientBoostingClassifier(early_stopping=False,\n",
        "                        l2_regularization=2.188553300996835e-10,\n",
        "                        learning_rate=0.06138190336151616, max_iter=512,\n",
        "                        max_leaf_nodes=20, n_iter_no_change=0,\n",
        "                        random_state=1, validation_fraction=None,\n",
        "                        warm_start=True), data.values, categorical_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IebHZrj3kSJz"
      },
      "source": [
        "### Convolution Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPxlcsQBkSJ0",
        "outputId": "89dc23f8-ccda-427d-eccd-922e25e6e017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "____________________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   Trainable  \n",
            "============================================================================\n",
            " conv1d (Conv1D)             (None, 20, 256)           1536      Y          \n",
            "                                                                            \n",
            " batch_normalization (BatchN  (None, 20, 256)          1024      Y          \n",
            " ormalization)                                                              \n",
            "                                                                            \n",
            " activation (Activation)     (None, 20, 256)           0         Y          \n",
            "                                                                            \n",
            " conv1d_1 (Conv1D)           (None, 16, 128)           163968    Y          \n",
            "                                                                            \n",
            " activation_1 (Activation)   (None, 16, 128)           0         Y          \n",
            "                                                                            \n",
            " dropout (Dropout)           (None, 16, 128)           0         Y          \n",
            "                                                                            \n",
            " max_pooling1d (MaxPooling1D  (None, 14, 128)          0         Y          \n",
            " )                                                                          \n",
            "                                                                            \n",
            " conv1d_2 (Conv1D)           (None, 10, 128)           82048     Y          \n",
            "                                                                            \n",
            " activation_2 (Activation)   (None, 10, 128)           0         Y          \n",
            "                                                                            \n",
            " batch_normalization_1 (Batc  (None, 10, 128)          512       Y          \n",
            " hNormalization)                                                            \n",
            "                                                                            \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         Y          \n",
            "                                                                            \n",
            " flatten (Flatten)           (None, 1280)              0         Y          \n",
            "                                                                            \n",
            " dense (Dense)               (None, 3)                 3843      Y          \n",
            "                                                                            \n",
            " activation_3 (Activation)   (None, 3)                 0         Y          \n",
            "                                                                            \n",
            "============================================================================\n",
            "Total params: 252,931\n",
            "Trainable params: 252,163\n",
            "Non-trainable params: 768\n",
            "____________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_model_0(input_shape=(24, 1), loss=MeanSquaredError(), optimizer=Adam(learning_rate=1e-5, epsilon=1e-6)):\n",
        "    if loss.__class__ == SparseCategoricalCrossentropy().__class__:\n",
        "        n_labels = 4\n",
        "        metrics = ['accuracy']\n",
        "        activation = 'softmax'\n",
        "    else:\n",
        "        n_labels = 3\n",
        "        metrics = ['mae']\n",
        "        activation = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(256, (5), input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv1D(128, (5)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(MaxPooling1D(n_labels, strides=1))\n",
        "\n",
        "    model.add(Conv1D(128, (5)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(n_labels))\n",
        "\n",
        "    model.add(Activation(activation))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "    return model\n",
        "build_model_0(input_shape=(data.iloc[0].shape[0],1)).summary(show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "S0zhxiRekSJ1"
      },
      "outputs": [],
      "source": [
        "def categorical_cross_validation(callbacks, no_epochs, batch_size, loss, optimizer, verbosity, num_folds):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "  fold_no = 1\n",
        "  \n",
        "  X = df.iloc[:,8:]\n",
        "  y = df.iloc[:,4:5]\n",
        "\n",
        "  for train, test in kfold.split(X, y):\n",
        "    model = build_model_0(input_shape=(data.shape[1], 1), loss=loss, optimizer=optimizer)\n",
        "    \n",
        "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
        "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
        "\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=no_epochs,\n",
        "                verbose=verbosity,\n",
        "                callbacks=callbacks,\n",
        "                workers=4)\n",
        "\n",
        "    scores = model.evaluate(X_test, y_test, verbose=verbosity)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Score per fold')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Dy_fALukSJ2",
        "outputId": "a2f56cc0-eb60-408a-caa2-7288bd636b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Score for fold 1: loss of 1.111961007118225; accuracy of 49.232158064842224%\n",
            "Training for fold 2 ...\n",
            "Score for fold 2: loss of 1.1252243518829346; accuracy of 48.73417615890503%\n",
            "Training for fold 3 ...\n",
            "Score for fold 3: loss of 1.1336780786514282; accuracy of 46.473780274391174%\n",
            "Training for fold 4 ...\n",
            "Score for fold 4: loss of 1.1383367776870728; accuracy of 46.383363008499146%\n",
            "Training for fold 5 ...\n",
            "Score for fold 5: loss of 1.1080365180969238; accuracy of 48.19168150424957%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 1.111961007118225 - Accuracy: 49.232158064842224%\n",
            "> Fold 2 - Loss: 1.1252243518829346 - Accuracy: 48.73417615890503%\n",
            "> Fold 3 - Loss: 1.1336780786514282 - Accuracy: 46.473780274391174%\n",
            "> Fold 4 - Loss: 1.1383367776870728 - Accuracy: 46.383363008499146%\n",
            "> Fold 5 - Loss: 1.1080365180969238 - Accuracy: 48.19168150424957%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 47.80303180217743 (+- 1.1698589134156916)\n",
            "> Loss: 1.123447346687317\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=10)\n",
        "no_epochs = 500 # try 300 or 700\n",
        "batch_size = 16 # try 16\n",
        "learning_rate=1e-5 # try 1e-4\n",
        "loss = SparseCategoricalCrossentropy()\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "verbosity = 0\n",
        "num_folds = 5\n",
        "\n",
        "categorical_cross_validation(callback, no_epochs, batch_size, loss, optimizer, verbosity, num_folds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm3wT0d8DiNY"
      },
      "source": [
        "### AutoKeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J3rMB1uDhmF",
        "outputId": "ad140d3e-4910-472a-c13a-8c9fe97a07a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 84 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.13287514448165894\n",
            "\n",
            "Best val_accuracy So Far: 0.743413507938385\n",
            "Total elapsed time: 00h 05m 42s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.6184 - accuracy: 0.2493\n",
            "Epoch 2/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.6064 - accuracy: 0.2522\n",
            "Epoch 3/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5952 - accuracy: 0.2592\n",
            "Epoch 4/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.5787 - accuracy: 0.2615\n",
            "Epoch 5/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5554 - accuracy: 0.2712\n",
            "Epoch 6/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5569 - accuracy: 0.2748\n",
            "Epoch 7/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5372 - accuracy: 0.2843\n",
            "Epoch 8/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5279 - accuracy: 0.2800\n",
            "Epoch 9/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5341 - accuracy: 0.2793\n",
            "Epoch 10/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5075 - accuracy: 0.2913\n",
            "Epoch 11/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.5006 - accuracy: 0.2879\n",
            "Epoch 12/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.4928 - accuracy: 0.2893\n",
            "Epoch 13/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.4752 - accuracy: 0.3051\n",
            "Epoch 14/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.4772 - accuracy: 0.2976\n",
            "Epoch 15/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4607 - accuracy: 0.3186\n",
            "Epoch 16/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4573 - accuracy: 0.3134\n",
            "Epoch 17/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.4506 - accuracy: 0.3189\n",
            "Epoch 18/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.3175\n",
            "Epoch 19/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4432 - accuracy: 0.3146\n",
            "Epoch 20/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4249 - accuracy: 0.3254\n",
            "Epoch 21/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4232 - accuracy: 0.3256\n",
            "Epoch 22/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4219 - accuracy: 0.3243\n",
            "Epoch 23/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.4109 - accuracy: 0.3227\n",
            "Epoch 24/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4008 - accuracy: 0.3266\n",
            "Epoch 25/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4167 - accuracy: 0.3288\n",
            "Epoch 26/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.4002 - accuracy: 0.3284\n",
            "Epoch 27/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3920 - accuracy: 0.3270\n",
            "Epoch 28/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3977 - accuracy: 0.3397\n",
            "Epoch 29/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3854 - accuracy: 0.3369\n",
            "Epoch 30/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3888 - accuracy: 0.3356\n",
            "Epoch 31/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3787 - accuracy: 0.3453\n",
            "Epoch 32/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3678 - accuracy: 0.3424\n",
            "Epoch 33/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3699 - accuracy: 0.3478\n",
            "Epoch 34/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3639 - accuracy: 0.3534\n",
            "Epoch 35/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3595 - accuracy: 0.3503\n",
            "Epoch 36/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3537 - accuracy: 0.3586\n",
            "Epoch 37/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3528 - accuracy: 0.3566\n",
            "Epoch 38/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3525 - accuracy: 0.3496\n",
            "Epoch 39/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3423 - accuracy: 0.3553\n",
            "Epoch 40/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3368 - accuracy: 0.3598\n",
            "Epoch 41/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3271 - accuracy: 0.3724\n",
            "Epoch 42/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3390 - accuracy: 0.3675\n",
            "Epoch 43/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3294 - accuracy: 0.3661\n",
            "Epoch 44/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3291 - accuracy: 0.3729\n",
            "Epoch 45/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3207 - accuracy: 0.3727\n",
            "Epoch 46/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3252 - accuracy: 0.3679\n",
            "Epoch 47/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3109 - accuracy: 0.3702\n",
            "Epoch 48/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3168 - accuracy: 0.3641\n",
            "Epoch 49/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3112 - accuracy: 0.3747\n",
            "Epoch 50/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3199 - accuracy: 0.3765\n",
            "Epoch 51/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2986 - accuracy: 0.3783\n",
            "Epoch 52/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3020 - accuracy: 0.3763\n",
            "Epoch 53/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.3055 - accuracy: 0.3751\n",
            "Epoch 54/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.3052 - accuracy: 0.3763\n",
            "Epoch 55/500\n",
            "277/277 [==============================] - 1s 3ms/step - loss: 1.2942 - accuracy: 0.3853\n",
            "Epoch 56/500\n",
            "277/277 [==============================] - 1s 3ms/step - loss: 1.3021 - accuracy: 0.3779\n",
            "Epoch 57/500\n",
            "277/277 [==============================] - 1s 3ms/step - loss: 1.2989 - accuracy: 0.3831\n",
            "Epoch 58/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2907 - accuracy: 0.3894\n",
            "Epoch 59/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2905 - accuracy: 0.3833\n",
            "Epoch 60/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2815 - accuracy: 0.3855\n",
            "Epoch 61/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2832 - accuracy: 0.3912\n",
            "Epoch 62/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2825 - accuracy: 0.3919\n",
            "Epoch 63/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2731 - accuracy: 0.3941\n",
            "Epoch 64/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2800 - accuracy: 0.3840\n",
            "Epoch 65/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2897 - accuracy: 0.3892\n",
            "Epoch 66/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2782 - accuracy: 0.3880\n",
            "Epoch 67/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2702 - accuracy: 0.3948\n",
            "Epoch 68/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2758 - accuracy: 0.3894\n",
            "Epoch 69/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2709 - accuracy: 0.4070\n",
            "Epoch 70/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2725 - accuracy: 0.3858\n",
            "Epoch 71/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2626 - accuracy: 0.4041\n",
            "Epoch 72/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2625 - accuracy: 0.3937\n",
            "Epoch 73/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2667 - accuracy: 0.3971\n",
            "Epoch 74/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2663 - accuracy: 0.3901\n",
            "Epoch 75/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2703 - accuracy: 0.3923\n",
            "Epoch 76/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2651 - accuracy: 0.3948\n",
            "Epoch 77/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2602 - accuracy: 0.3998\n",
            "Epoch 78/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2579 - accuracy: 0.4009\n",
            "Epoch 79/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2604 - accuracy: 0.3964\n",
            "Epoch 80/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2578 - accuracy: 0.3982\n",
            "Epoch 81/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2541 - accuracy: 0.4007\n",
            "Epoch 82/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2433 - accuracy: 0.4079\n",
            "Epoch 83/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2439 - accuracy: 0.4160\n",
            "Epoch 84/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2561 - accuracy: 0.3934\n",
            "Epoch 85/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2553 - accuracy: 0.3946\n",
            "Epoch 86/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2485 - accuracy: 0.4027\n",
            "Epoch 87/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2464 - accuracy: 0.4038\n",
            "Epoch 88/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2455 - accuracy: 0.4151\n",
            "Epoch 89/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2552 - accuracy: 0.3934\n",
            "Epoch 90/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2382 - accuracy: 0.4140\n",
            "Epoch 91/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2425 - accuracy: 0.4084\n",
            "Epoch 92/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2421 - accuracy: 0.4077\n",
            "Epoch 93/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2395 - accuracy: 0.4113\n",
            "Epoch 94/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2377 - accuracy: 0.4160\n",
            "Epoch 95/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2326 - accuracy: 0.4138\n",
            "Epoch 96/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2348 - accuracy: 0.4142\n",
            "Epoch 97/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2290 - accuracy: 0.4131\n",
            "Epoch 98/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2317 - accuracy: 0.4203\n",
            "Epoch 99/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2321 - accuracy: 0.4174\n",
            "Epoch 100/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2341 - accuracy: 0.4149\n",
            "Epoch 101/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2311 - accuracy: 0.4219\n",
            "Epoch 102/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2261 - accuracy: 0.4188\n",
            "Epoch 103/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2408 - accuracy: 0.4054\n",
            "Epoch 104/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2276 - accuracy: 0.4217\n",
            "Epoch 105/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2251 - accuracy: 0.4249\n",
            "Epoch 106/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2260 - accuracy: 0.4210\n",
            "Epoch 107/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2312 - accuracy: 0.4206\n",
            "Epoch 108/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2130 - accuracy: 0.4375\n",
            "Epoch 109/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2156 - accuracy: 0.4208\n",
            "Epoch 110/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2247 - accuracy: 0.4154\n",
            "Epoch 111/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2121 - accuracy: 0.4285\n",
            "Epoch 112/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2205 - accuracy: 0.4142\n",
            "Epoch 113/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2211 - accuracy: 0.4221\n",
            "Epoch 114/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2182 - accuracy: 0.4231\n",
            "Epoch 115/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2244 - accuracy: 0.4118\n",
            "Epoch 116/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2198 - accuracy: 0.4221\n",
            "Epoch 117/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2149 - accuracy: 0.4172\n",
            "Epoch 118/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2138 - accuracy: 0.4224\n",
            "Epoch 119/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2035 - accuracy: 0.4357\n",
            "Epoch 120/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2058 - accuracy: 0.4258\n",
            "Epoch 121/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2138 - accuracy: 0.4212\n",
            "Epoch 122/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2099 - accuracy: 0.4260\n",
            "Epoch 123/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2092 - accuracy: 0.4321\n",
            "Epoch 124/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2059 - accuracy: 0.4316\n",
            "Epoch 125/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2027 - accuracy: 0.4285\n",
            "Epoch 126/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2132 - accuracy: 0.4357\n",
            "Epoch 127/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1999 - accuracy: 0.4269\n",
            "Epoch 128/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2048 - accuracy: 0.4353\n",
            "Epoch 129/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2038 - accuracy: 0.4169\n",
            "Epoch 130/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2005 - accuracy: 0.4292\n",
            "Epoch 131/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2052 - accuracy: 0.4371\n",
            "Epoch 132/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2027 - accuracy: 0.4339\n",
            "Epoch 133/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1976 - accuracy: 0.4373\n",
            "Epoch 134/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.2019 - accuracy: 0.4384\n",
            "Epoch 135/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2036 - accuracy: 0.4346\n",
            "Epoch 136/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1948 - accuracy: 0.4357\n",
            "Epoch 137/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.2009 - accuracy: 0.4359\n",
            "Epoch 138/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1974 - accuracy: 0.4262\n",
            "Epoch 139/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1920 - accuracy: 0.4441\n",
            "Epoch 140/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1972 - accuracy: 0.4323\n",
            "Epoch 141/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1959 - accuracy: 0.4386\n",
            "Epoch 142/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1921 - accuracy: 0.4479\n",
            "Epoch 143/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1954 - accuracy: 0.4398\n",
            "Epoch 144/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1884 - accuracy: 0.4447\n",
            "Epoch 145/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1993 - accuracy: 0.4217\n",
            "Epoch 146/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1892 - accuracy: 0.4377\n",
            "Epoch 147/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1878 - accuracy: 0.4380\n",
            "Epoch 148/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1906 - accuracy: 0.4416\n",
            "Epoch 149/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1892 - accuracy: 0.4400\n",
            "Epoch 150/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1927 - accuracy: 0.4359\n",
            "Epoch 151/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1881 - accuracy: 0.4524\n",
            "Epoch 152/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1887 - accuracy: 0.4319\n",
            "Epoch 153/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1916 - accuracy: 0.4398\n",
            "Epoch 154/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1933 - accuracy: 0.4411\n",
            "Epoch 155/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1909 - accuracy: 0.4362\n",
            "Epoch 156/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1851 - accuracy: 0.4423\n",
            "Epoch 157/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1863 - accuracy: 0.4418\n",
            "Epoch 158/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1870 - accuracy: 0.4348\n",
            "Epoch 159/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1875 - accuracy: 0.4409\n",
            "Epoch 160/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1809 - accuracy: 0.4362\n",
            "Epoch 161/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1781 - accuracy: 0.4527\n",
            "Epoch 162/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1803 - accuracy: 0.4441\n",
            "Epoch 163/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1825 - accuracy: 0.4434\n",
            "Epoch 164/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1887 - accuracy: 0.4456\n",
            "Epoch 165/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1778 - accuracy: 0.4393\n",
            "Epoch 166/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1771 - accuracy: 0.4405\n",
            "Epoch 167/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1794 - accuracy: 0.4409\n",
            "Epoch 168/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1792 - accuracy: 0.4337\n",
            "Epoch 169/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1788 - accuracy: 0.4443\n",
            "Epoch 170/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1808 - accuracy: 0.4461\n",
            "Epoch 171/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1819 - accuracy: 0.4502\n",
            "Epoch 172/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1703 - accuracy: 0.4524\n",
            "Epoch 173/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1733 - accuracy: 0.4522\n",
            "Epoch 174/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1766 - accuracy: 0.4518\n",
            "Epoch 175/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1795 - accuracy: 0.4418\n",
            "Epoch 176/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1732 - accuracy: 0.4583\n",
            "Epoch 177/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1796 - accuracy: 0.4445\n",
            "Epoch 178/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1830 - accuracy: 0.4395\n",
            "Epoch 179/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1774 - accuracy: 0.4411\n",
            "Epoch 180/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1671 - accuracy: 0.4601\n",
            "Epoch 181/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1742 - accuracy: 0.4545\n",
            "Epoch 182/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1713 - accuracy: 0.4488\n",
            "Epoch 183/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1690 - accuracy: 0.4642\n",
            "Epoch 184/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1813 - accuracy: 0.4391\n",
            "Epoch 185/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1742 - accuracy: 0.4493\n",
            "Epoch 186/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1744 - accuracy: 0.4549\n",
            "Epoch 187/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1728 - accuracy: 0.4536\n",
            "Epoch 188/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1705 - accuracy: 0.4558\n",
            "Epoch 189/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1689 - accuracy: 0.4533\n",
            "Epoch 190/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1712 - accuracy: 0.4524\n",
            "Epoch 191/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1722 - accuracy: 0.4438\n",
            "Epoch 192/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1662 - accuracy: 0.4560\n",
            "Epoch 193/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1670 - accuracy: 0.4518\n",
            "Epoch 194/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1666 - accuracy: 0.4504\n",
            "Epoch 195/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1584 - accuracy: 0.4536\n",
            "Epoch 196/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1630 - accuracy: 0.4558\n",
            "Epoch 197/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1686 - accuracy: 0.4450\n",
            "Epoch 198/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1696 - accuracy: 0.4633\n",
            "Epoch 199/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1650 - accuracy: 0.4522\n",
            "Epoch 200/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1629 - accuracy: 0.4565\n",
            "Epoch 201/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1634 - accuracy: 0.4486\n",
            "Epoch 202/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1587 - accuracy: 0.4633\n",
            "Epoch 203/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1661 - accuracy: 0.4554\n",
            "Epoch 204/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1618 - accuracy: 0.4545\n",
            "Epoch 205/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1562 - accuracy: 0.4737\n",
            "Epoch 206/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1608 - accuracy: 0.4612\n",
            "Epoch 207/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1561 - accuracy: 0.4610\n",
            "Epoch 208/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.4642\n",
            "Epoch 209/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1592 - accuracy: 0.4547\n",
            "Epoch 210/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1646 - accuracy: 0.4472\n",
            "Epoch 211/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1581 - accuracy: 0.4610\n",
            "Epoch 212/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1526 - accuracy: 0.4615\n",
            "Epoch 213/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1554 - accuracy: 0.4576\n",
            "Epoch 214/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1594 - accuracy: 0.4635\n",
            "Epoch 215/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1591 - accuracy: 0.4583\n",
            "Epoch 216/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1639 - accuracy: 0.4599\n",
            "Epoch 217/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1493 - accuracy: 0.4626\n",
            "Epoch 218/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1532 - accuracy: 0.4597\n",
            "Epoch 219/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1571 - accuracy: 0.4569\n",
            "Epoch 220/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1454 - accuracy: 0.4685\n",
            "Epoch 221/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1608 - accuracy: 0.4551\n",
            "Epoch 222/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1533 - accuracy: 0.4597\n",
            "Epoch 223/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1514 - accuracy: 0.4633\n",
            "Epoch 224/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1635 - accuracy: 0.4536\n",
            "Epoch 225/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1561 - accuracy: 0.4572\n",
            "Epoch 226/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1496 - accuracy: 0.4624\n",
            "Epoch 227/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1521 - accuracy: 0.4628\n",
            "Epoch 228/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1476 - accuracy: 0.4637\n",
            "Epoch 229/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1530 - accuracy: 0.4606\n",
            "Epoch 230/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1547 - accuracy: 0.4642\n",
            "Epoch 231/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1437 - accuracy: 0.4631\n",
            "Epoch 232/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1502 - accuracy: 0.4554\n",
            "Epoch 233/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1578 - accuracy: 0.4567\n",
            "Epoch 234/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1394 - accuracy: 0.4746\n",
            "Epoch 235/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1496 - accuracy: 0.4606\n",
            "Epoch 236/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1430 - accuracy: 0.4748\n",
            "Epoch 237/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1436 - accuracy: 0.4680\n",
            "Epoch 238/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1500 - accuracy: 0.4631\n",
            "Epoch 239/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1406 - accuracy: 0.4741\n",
            "Epoch 240/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1435 - accuracy: 0.4673\n",
            "Epoch 241/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1538 - accuracy: 0.4592\n",
            "Epoch 242/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1416 - accuracy: 0.4685\n",
            "Epoch 243/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1455 - accuracy: 0.4678\n",
            "Epoch 244/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1537 - accuracy: 0.4549\n",
            "Epoch 245/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1391 - accuracy: 0.4755\n",
            "Epoch 246/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1430 - accuracy: 0.4669\n",
            "Epoch 247/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1453 - accuracy: 0.4712\n",
            "Epoch 248/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1429 - accuracy: 0.4671\n",
            "Epoch 249/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1487 - accuracy: 0.4529\n",
            "Epoch 250/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1443 - accuracy: 0.4617\n",
            "Epoch 251/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1464 - accuracy: 0.4615\n",
            "Epoch 252/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1494 - accuracy: 0.4569\n",
            "Epoch 253/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1410 - accuracy: 0.4703\n",
            "Epoch 254/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1435 - accuracy: 0.4714\n",
            "Epoch 255/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1405 - accuracy: 0.4610\n",
            "Epoch 256/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1394 - accuracy: 0.4721\n",
            "Epoch 257/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1370 - accuracy: 0.4739\n",
            "Epoch 258/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1446 - accuracy: 0.4673\n",
            "Epoch 259/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1376 - accuracy: 0.4716\n",
            "Epoch 260/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1472 - accuracy: 0.4612\n",
            "Epoch 261/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1350 - accuracy: 0.4689\n",
            "Epoch 262/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1402 - accuracy: 0.4678\n",
            "Epoch 263/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1412 - accuracy: 0.4664\n",
            "Epoch 264/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1295 - accuracy: 0.4798\n",
            "Epoch 265/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1400 - accuracy: 0.4628\n",
            "Epoch 266/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1443 - accuracy: 0.4705\n",
            "Epoch 267/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1387 - accuracy: 0.4757\n",
            "Epoch 268/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1413 - accuracy: 0.4701\n",
            "Epoch 269/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1338 - accuracy: 0.4768\n",
            "Epoch 270/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1369 - accuracy: 0.4698\n",
            "Epoch 271/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1303 - accuracy: 0.4802\n",
            "Epoch 272/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1320 - accuracy: 0.4716\n",
            "Epoch 273/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1366 - accuracy: 0.4696\n",
            "Epoch 274/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1376 - accuracy: 0.4696\n",
            "Epoch 275/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1325 - accuracy: 0.4728\n",
            "Epoch 276/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1336 - accuracy: 0.4737\n",
            "Epoch 277/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1337 - accuracy: 0.4725\n",
            "Epoch 278/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1332 - accuracy: 0.4766\n",
            "Epoch 279/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1337 - accuracy: 0.4685\n",
            "Epoch 280/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1402 - accuracy: 0.4653\n",
            "Epoch 281/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1388 - accuracy: 0.4646\n",
            "Epoch 282/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1345 - accuracy: 0.4644\n",
            "Epoch 283/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1375 - accuracy: 0.4644\n",
            "Epoch 284/500\n",
            "277/277 [==============================] - 0s 2ms/step - loss: 1.1423 - accuracy: 0.4662\n",
            "Epoch 285/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1371 - accuracy: 0.4664\n",
            "Epoch 286/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1407 - accuracy: 0.4667\n",
            "Epoch 287/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1290 - accuracy: 0.4782\n",
            "Epoch 288/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1341 - accuracy: 0.4759\n",
            "Epoch 289/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1327 - accuracy: 0.4676\n",
            "Epoch 290/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1329 - accuracy: 0.4698\n",
            "Epoch 291/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1311 - accuracy: 0.4716\n",
            "Epoch 292/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1312 - accuracy: 0.4802\n",
            "Epoch 293/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1353 - accuracy: 0.4775\n",
            "Epoch 294/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1281 - accuracy: 0.4777\n",
            "Epoch 295/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1265 - accuracy: 0.4750\n",
            "Epoch 296/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1357 - accuracy: 0.4716\n",
            "Epoch 297/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1344 - accuracy: 0.4678\n",
            "Epoch 298/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1280 - accuracy: 0.4755\n",
            "Epoch 299/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1335 - accuracy: 0.4671\n",
            "Epoch 300/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1228 - accuracy: 0.4714\n",
            "Epoch 301/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1274 - accuracy: 0.4805\n",
            "Epoch 302/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1279 - accuracy: 0.4732\n",
            "Epoch 303/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1289 - accuracy: 0.4728\n",
            "Epoch 304/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1341 - accuracy: 0.4814\n",
            "Epoch 305/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1318 - accuracy: 0.4730\n",
            "Epoch 306/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1214 - accuracy: 0.4768\n",
            "Epoch 307/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1312 - accuracy: 0.4689\n",
            "Epoch 308/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1356 - accuracy: 0.4728\n",
            "Epoch 309/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1260 - accuracy: 0.4773\n",
            "Epoch 310/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1284 - accuracy: 0.4798\n",
            "Epoch 311/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1238 - accuracy: 0.4782\n",
            "Epoch 312/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1264 - accuracy: 0.4694\n",
            "Epoch 313/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1292 - accuracy: 0.4716\n",
            "Epoch 314/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1203 - accuracy: 0.4748\n",
            "Epoch 315/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1308 - accuracy: 0.4798\n",
            "Epoch 316/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1201 - accuracy: 0.4899\n",
            "Epoch 317/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1201 - accuracy: 0.4814\n",
            "Epoch 318/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1329 - accuracy: 0.4728\n",
            "Epoch 319/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1322 - accuracy: 0.4701\n",
            "Epoch 320/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1277 - accuracy: 0.4721\n",
            "Epoch 321/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1229 - accuracy: 0.4791\n",
            "Epoch 322/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1269 - accuracy: 0.4777\n",
            "Epoch 323/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1247 - accuracy: 0.4784\n",
            "Epoch 324/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1196 - accuracy: 0.4807\n",
            "Epoch 325/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1323 - accuracy: 0.4680\n",
            "Epoch 326/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1281 - accuracy: 0.4798\n",
            "Epoch 327/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1235 - accuracy: 0.4832\n",
            "Epoch 328/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1234 - accuracy: 0.4847\n",
            "Epoch 329/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1216 - accuracy: 0.4653\n",
            "Epoch 330/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1157 - accuracy: 0.4847\n",
            "Epoch 331/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1204 - accuracy: 0.4838\n",
            "Epoch 332/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1211 - accuracy: 0.4811\n",
            "Epoch 333/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1154 - accuracy: 0.4850\n",
            "Epoch 334/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1170 - accuracy: 0.4829\n",
            "Epoch 335/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1218 - accuracy: 0.4730\n",
            "Epoch 336/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1244 - accuracy: 0.4705\n",
            "Epoch 337/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1241 - accuracy: 0.4753\n",
            "Epoch 338/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1296 - accuracy: 0.4660\n",
            "Epoch 339/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1240 - accuracy: 0.4703\n",
            "Epoch 340/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1252 - accuracy: 0.4696\n",
            "Epoch 341/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1221 - accuracy: 0.4782\n",
            "Epoch 342/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1184 - accuracy: 0.4888\n",
            "Epoch 343/500\n",
            "277/277 [==============================] - 1s 3ms/step - loss: 1.1259 - accuracy: 0.4710\n",
            "Epoch 344/500\n",
            "277/277 [==============================] - 1s 3ms/step - loss: 1.1161 - accuracy: 0.4816\n",
            "Epoch 345/500\n",
            "277/277 [==============================] - 1s 3ms/step - loss: 1.1178 - accuracy: 0.4775\n",
            "Epoch 346/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1202 - accuracy: 0.4782\n",
            "Epoch 347/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1166 - accuracy: 0.4931\n",
            "Epoch 348/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1154 - accuracy: 0.4811\n",
            "Epoch 349/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1132 - accuracy: 0.4802\n",
            "Epoch 350/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1263 - accuracy: 0.4789\n",
            "Epoch 351/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1201 - accuracy: 0.4768\n",
            "Epoch 352/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1160 - accuracy: 0.4730\n",
            "Epoch 353/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1167 - accuracy: 0.4854\n",
            "Epoch 354/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1191 - accuracy: 0.4744\n",
            "Epoch 355/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1202 - accuracy: 0.4807\n",
            "Epoch 356/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1172 - accuracy: 0.4750\n",
            "Epoch 357/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1224 - accuracy: 0.4734\n",
            "Epoch 358/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1216 - accuracy: 0.4811\n",
            "Epoch 359/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1123 - accuracy: 0.4818\n",
            "Epoch 360/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1231 - accuracy: 0.4739\n",
            "Epoch 361/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1132 - accuracy: 0.4823\n",
            "Epoch 362/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1182 - accuracy: 0.4884\n",
            "Epoch 363/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1203 - accuracy: 0.4793\n",
            "Epoch 364/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1156 - accuracy: 0.4841\n",
            "Epoch 365/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1148 - accuracy: 0.4818\n",
            "Epoch 366/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1152 - accuracy: 0.4820\n",
            "Epoch 367/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1200 - accuracy: 0.4744\n",
            "Epoch 368/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1119 - accuracy: 0.4850\n",
            "Epoch 369/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1098 - accuracy: 0.4877\n",
            "Epoch 370/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1155 - accuracy: 0.4841\n",
            "Epoch 371/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1126 - accuracy: 0.4841\n",
            "Epoch 372/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1144 - accuracy: 0.4832\n",
            "Epoch 373/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1176 - accuracy: 0.4798\n",
            "Epoch 374/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1184 - accuracy: 0.4872\n",
            "Epoch 375/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1169 - accuracy: 0.4768\n",
            "Epoch 376/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1164 - accuracy: 0.4845\n",
            "Epoch 377/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1122 - accuracy: 0.4782\n",
            "Epoch 378/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1079 - accuracy: 0.4816\n",
            "Epoch 379/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1115 - accuracy: 0.4899\n",
            "Epoch 380/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1135 - accuracy: 0.4856\n",
            "Epoch 381/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1123 - accuracy: 0.4834\n",
            "Epoch 382/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1151 - accuracy: 0.4841\n",
            "Epoch 383/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1133 - accuracy: 0.4838\n",
            "Epoch 384/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1179 - accuracy: 0.4827\n",
            "Epoch 385/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1111 - accuracy: 0.4863\n",
            "Epoch 386/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1139 - accuracy: 0.4863\n",
            "Epoch 387/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1153 - accuracy: 0.4786\n",
            "Epoch 388/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1028 - accuracy: 0.4929\n",
            "Epoch 389/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1034 - accuracy: 0.4938\n",
            "Epoch 390/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1161 - accuracy: 0.4816\n",
            "Epoch 391/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1097 - accuracy: 0.4843\n",
            "Epoch 392/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1099 - accuracy: 0.4856\n",
            "Epoch 393/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1152 - accuracy: 0.4809\n",
            "Epoch 394/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1114 - accuracy: 0.4768\n",
            "Epoch 395/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1091 - accuracy: 0.4829\n",
            "Epoch 396/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1112 - accuracy: 0.4906\n",
            "Epoch 397/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1013 - accuracy: 0.4841\n",
            "Epoch 398/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1153 - accuracy: 0.4728\n",
            "Epoch 399/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1149 - accuracy: 0.4786\n",
            "Epoch 400/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1035 - accuracy: 0.4933\n",
            "Epoch 401/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1089 - accuracy: 0.4983\n",
            "Epoch 402/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1098 - accuracy: 0.4863\n",
            "Epoch 403/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1122 - accuracy: 0.4838\n",
            "Epoch 404/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1008 - accuracy: 0.4823\n",
            "Epoch 405/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1084 - accuracy: 0.4847\n",
            "Epoch 406/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1112 - accuracy: 0.4836\n",
            "Epoch 407/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1031 - accuracy: 0.4911\n",
            "Epoch 408/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1023 - accuracy: 0.4829\n",
            "Epoch 409/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1041 - accuracy: 0.4927\n",
            "Epoch 410/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0990 - accuracy: 0.4960\n",
            "Epoch 411/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1081 - accuracy: 0.4890\n",
            "Epoch 412/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1064 - accuracy: 0.4872\n",
            "Epoch 413/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1122 - accuracy: 0.4795\n",
            "Epoch 414/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1101 - accuracy: 0.4868\n",
            "Epoch 415/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1058 - accuracy: 0.4976\n",
            "Epoch 416/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1079 - accuracy: 0.4881\n",
            "Epoch 417/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1083 - accuracy: 0.4757\n",
            "Epoch 418/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1097 - accuracy: 0.4861\n",
            "Epoch 419/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1066 - accuracy: 0.4940\n",
            "Epoch 420/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1051 - accuracy: 0.4895\n",
            "Epoch 421/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1051 - accuracy: 0.4841\n",
            "Epoch 422/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0993 - accuracy: 0.4915\n",
            "Epoch 423/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1162 - accuracy: 0.4786\n",
            "Epoch 424/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1038 - accuracy: 0.4890\n",
            "Epoch 425/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1045 - accuracy: 0.4927\n",
            "Epoch 426/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1083 - accuracy: 0.4938\n",
            "Epoch 427/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1019 - accuracy: 0.4911\n",
            "Epoch 428/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1045 - accuracy: 0.4825\n",
            "Epoch 429/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0990 - accuracy: 0.4936\n",
            "Epoch 430/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1053 - accuracy: 0.4899\n",
            "Epoch 431/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1073 - accuracy: 0.4888\n",
            "Epoch 432/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1034 - accuracy: 0.4927\n",
            "Epoch 433/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.4940\n",
            "Epoch 434/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0941 - accuracy: 0.4940\n",
            "Epoch 435/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1061 - accuracy: 0.4938\n",
            "Epoch 436/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0994 - accuracy: 0.4875\n",
            "Epoch 437/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0960 - accuracy: 0.4870\n",
            "Epoch 438/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1054 - accuracy: 0.4886\n",
            "Epoch 439/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0984 - accuracy: 0.4918\n",
            "Epoch 440/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0977 - accuracy: 0.5003\n",
            "Epoch 441/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1103 - accuracy: 0.4814\n",
            "Epoch 442/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1041 - accuracy: 0.4884\n",
            "Epoch 443/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.4897\n",
            "Epoch 444/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1013 - accuracy: 0.4936\n",
            "Epoch 445/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1004 - accuracy: 0.4927\n",
            "Epoch 446/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0972 - accuracy: 0.4976\n",
            "Epoch 447/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1015 - accuracy: 0.4852\n",
            "Epoch 448/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0964 - accuracy: 0.4967\n",
            "Epoch 449/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0989 - accuracy: 0.4933\n",
            "Epoch 450/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1091 - accuracy: 0.4899\n",
            "Epoch 451/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0964 - accuracy: 0.4983\n",
            "Epoch 452/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1018 - accuracy: 0.4940\n",
            "Epoch 453/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1078 - accuracy: 0.4829\n",
            "Epoch 454/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0977 - accuracy: 0.4985\n",
            "Epoch 455/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0960 - accuracy: 0.4958\n",
            "Epoch 456/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1011 - accuracy: 0.4963\n",
            "Epoch 457/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1103 - accuracy: 0.4791\n",
            "Epoch 458/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1061 - accuracy: 0.4834\n",
            "Epoch 459/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0934 - accuracy: 0.5062\n",
            "Epoch 460/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0890 - accuracy: 0.4951\n",
            "Epoch 461/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.4890\n",
            "Epoch 462/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0936 - accuracy: 0.4945\n",
            "Epoch 463/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1012 - accuracy: 0.4863\n",
            "Epoch 464/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0975 - accuracy: 0.4963\n",
            "Epoch 465/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0995 - accuracy: 0.4929\n",
            "Epoch 466/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0958 - accuracy: 0.4933\n",
            "Epoch 467/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0970 - accuracy: 0.4958\n",
            "Epoch 468/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0901 - accuracy: 0.4954\n",
            "Epoch 469/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0965 - accuracy: 0.5012\n",
            "Epoch 470/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0984 - accuracy: 0.4974\n",
            "Epoch 471/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1027 - accuracy: 0.4927\n",
            "Epoch 472/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1073 - accuracy: 0.4893\n",
            "Epoch 473/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.1009 - accuracy: 0.4985\n",
            "Epoch 474/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.4949\n",
            "Epoch 475/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0926 - accuracy: 0.4954\n",
            "Epoch 476/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0955 - accuracy: 0.4981\n",
            "Epoch 477/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0923 - accuracy: 0.4983\n",
            "Epoch 478/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0909 - accuracy: 0.4936\n",
            "Epoch 479/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0954 - accuracy: 0.4904\n",
            "Epoch 480/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0965 - accuracy: 0.4938\n",
            "Epoch 481/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0976 - accuracy: 0.4924\n",
            "Epoch 482/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0951 - accuracy: 0.4940\n",
            "Epoch 483/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0913 - accuracy: 0.4963\n",
            "Epoch 484/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0891 - accuracy: 0.4994\n",
            "Epoch 485/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0974 - accuracy: 0.4940\n",
            "Epoch 486/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0913 - accuracy: 0.4949\n",
            "Epoch 487/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0984 - accuracy: 0.4888\n",
            "Epoch 488/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0941 - accuracy: 0.4958\n",
            "Epoch 489/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0956 - accuracy: 0.4979\n",
            "Epoch 490/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0957 - accuracy: 0.4908\n",
            "Epoch 491/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0881 - accuracy: 0.4994\n",
            "Epoch 492/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0977 - accuracy: 0.4983\n",
            "Epoch 493/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0925 - accuracy: 0.4938\n",
            "Epoch 494/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0944 - accuracy: 0.5010\n",
            "Epoch 495/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0974 - accuracy: 0.4999\n",
            "Epoch 496/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0944 - accuracy: 0.4908\n",
            "Epoch 497/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0964 - accuracy: 0.4997\n",
            "Epoch 498/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0912 - accuracy: 0.4951\n",
            "Epoch 499/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0989 - accuracy: 0.4947\n",
            "Epoch 500/500\n",
            "277/277 [==============================] - 1s 2ms/step - loss: 1.0918 - accuracy: 0.5003\n",
            "INFO:tensorflow:Assets written to: best_regression_keras_model_fold_5/structured_data_classifier/best_model/assets\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 24)]              0         \n",
            "                                                                 \n",
            " multi_category_encoding (Mu  (None, 24)               0         \n",
            " ltiCategoryEncoding)                                            \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 24)               49        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                400       \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 16)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 4)                0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 517\n",
            "Trainable params: 468\n",
            "Non-trainable params: 49\n",
            "_________________________________________________________________\n",
            "None\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0476 - accuracy: 0.5371\n",
            "Score for fold 5: Loss of 1.0476468801498413; Accuracy of 53.707051277160645%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 1.0572731494903564 - Accuracy: 52.30352282524109%\n",
            "> Fold 2 - Loss: 1.0707553625106812 - Accuracy: 55.33453822135925%\n",
            "> Fold 3 - Loss: 1.545008897781372 - Accuracy: 28.119349479675293%\n",
            "> Fold 4 - Loss: 1.5401153564453125 - Accuracy: 26.582279801368713%\n",
            "> Fold 5 - Loss: 1.0476468801498413 - Accuracy: 53.707051277160645%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 43.209348320961 (+- 12.993024897819918)\n",
            "> Loss: 1.2521599292755128\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def categorical_cross_validation2(no_epochs, batch_size, loss, optimizer, verbosity, num_folds):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "  fold_no = 1\n",
        "  \n",
        "  X = df.iloc[:,8:]\n",
        "  y = df.iloc[:,4:5]\n",
        "\n",
        "  for train, test in kfold.split(X, y):\n",
        "    model = ak.StructuredDataClassifier(overwrite=True, max_trials=100, seed=1, directory=f\"best_regression_keras_model_fold_{fold_no}\")\n",
        "    \n",
        "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
        "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
        "\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=no_epochs,\n",
        "                verbose=verbosity,\n",
        "                callbacks=[EarlyStopping()],\n",
        "                workers=8)\n",
        "  \n",
        "    print(model.export_model().summary())\n",
        "\n",
        "    scores = model.evaluate(X_test, y_test, verbose=verbosity)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: Loss of {scores[0]}; Accuracy of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Score per fold')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "\n",
        "# classifier that tries 100 different keras classifier models\n",
        "no_epochs = 500 # try 300 or 700\n",
        "batch_size = 16 # try 16\n",
        "learning_rate=1e-5 # try 1e-4\n",
        "loss = SparseCategoricalCrossentropy()\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "verbosity = 1\n",
        "num_folds = 5\n",
        "\n",
        "categorical_cross_validation2(no_epochs, batch_size, loss, optimizer, verbosity, num_folds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing with Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorical_cross_validation4(model, verbosity, num_folds):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "  fold_no = 1\n",
        "\n",
        "  X = df.iloc[:,8:]\n",
        "  y = df.iloc[:,4:5]\n",
        "\n",
        "  for train, test in kfold.split(X, y):    \n",
        "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
        "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
        "\n",
        "    y_test = y_test.astype('str')\n",
        "    y_test = OneHotEncoder().fit_transform(y_test).toarray()\n",
        "    print(y_test)\n",
        "\n",
        "    scores = model.evaluate(X_test, y_test, verbose=verbosity)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: Loss of {scores[0]}; Accuracy of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Score per fold')\n",
        "    for i in range(0, len(acc_per_fold)):\n",
        "      print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 24)]              0         \n",
            "                                                                 \n",
            " multi_category_encoding (Mu  (None, 24)               0         \n",
            " ltiCategoryEncoding)                                            \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 24)               49        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3200      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 4)                0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,381\n",
            "Trainable params: 5,332\n",
            "Non-trainable params: 49\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "35/35 [==============================] - 0s 589us/step - loss: 0.9041 - accuracy: 0.5980\n",
            "Score for fold 1: Loss of 0.9041263461112976; Accuracy of 59.801262617111206%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 0.9041263461112976 - Accuracy: 59.801262617111206%\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "35/35 [==============================] - 0s 622us/step - loss: 1.0718 - accuracy: 0.5506\n",
            "Score for fold 2: Loss of 1.0717626810073853; Accuracy of 55.063289403915405%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 0.9041263461112976 - Accuracy: 59.801262617111206%\n",
            "> Fold 2 - Loss: 1.0717626810073853 - Accuracy: 55.063289403915405%\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "35/35 [==============================] - 0s 583us/step - loss: 0.9163 - accuracy: 0.5995\n",
            "Score for fold 3: Loss of 0.9162515997886658; Accuracy of 59.94575023651123%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 0.9041263461112976 - Accuracy: 59.801262617111206%\n",
            "> Fold 2 - Loss: 1.0717626810073853 - Accuracy: 55.063289403915405%\n",
            "> Fold 3 - Loss: 0.9162515997886658 - Accuracy: 59.94575023651123%\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "35/35 [==============================] - 0s 638us/step - loss: 0.8775 - accuracy: 0.6175\n",
            "Score for fold 4: Loss of 0.8775064945220947; Accuracy of 61.75406575202942%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 0.9041263461112976 - Accuracy: 59.801262617111206%\n",
            "> Fold 2 - Loss: 1.0717626810073853 - Accuracy: 55.063289403915405%\n",
            "> Fold 3 - Loss: 0.9162515997886658 - Accuracy: 59.94575023651123%\n",
            "> Fold 4 - Loss: 0.8775064945220947 - Accuracy: 61.75406575202942%\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "35/35 [==============================] - 0s 614us/step - loss: 0.8672 - accuracy: 0.6094\n",
            "Score for fold 5: Loss of 0.8672279715538025; Accuracy of 60.94032526016235%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 0.9041263461112976 - Accuracy: 59.801262617111206%\n",
            "> Fold 2 - Loss: 1.0717626810073853 - Accuracy: 55.063289403915405%\n",
            "> Fold 3 - Loss: 0.9162515997886658 - Accuracy: 59.94575023651123%\n",
            "> Fold 4 - Loss: 0.8775064945220947 - Accuracy: 61.75406575202942%\n",
            "> Fold 5 - Loss: 0.8672279715538025 - Accuracy: 60.94032526016235%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 59.50093865394592 (+- 2.3293431784692173)\n",
            "> Loss: 0.9273750185966492\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(f\"{os.path.abspath('./../../../')}/Audio_Sentiment_Analysis/iemocap/data/categorical_keras_model_fold_2/structured_data_classifier/best_model\", custom_objects=ak.CUSTOM_OBJECTS)\n",
        "model.summary()\n",
        "categorical_cross_validation4(model, 1, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLKviaODSXAB"
      },
      "source": [
        "## Mel-Spectogram as the Input Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dqeC_eLUSXAC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Audio Files: 10039\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion_Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <th>0</th>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <th>1</th>\n",
              "      <td>1636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <th>3</th>\n",
              "      <td>1708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <th>2</th>\n",
              "      <td>1084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Emotion\n",
              "                     count\n",
              "Emotion Emotion_Id        \n",
              "angry   0             1103\n",
              "happy   1             1636\n",
              "neutral 3             1708\n",
              "sad     2             1084"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_df = pd.read_csv(RAW_AUDIO_FILES)\n",
        "print(f\"Number of Audio Files: {raw_df.shape[0]}\")\n",
        "raw_df = raw_df.set_index('File')\n",
        "raw_df_soa = raw_df[raw_df['Emotion'].isin({'angry', 'neutral', 'sad', 'happy', 'excited'})]\n",
        "raw_df_soa.loc[raw_df_soa['Emotion'] == 'excited', 'Emotion'] = 'happy'\n",
        "raw_df_soa.loc[raw_df_soa['Emotion_Id'] == 5, 'Emotion_Id'] = 1\n",
        "raw_df_soa.groupby(['Emotion', 'Emotion_Id']).agg({'Emotion': ['count']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def get_signal_and_label(audio_file):\n",
        "    audio_file = str(bytes.decode(audio_file.numpy()))\n",
        "    y, sr = librosa.load(audio_file, sr=None, res_type='kaiser_fast')\n",
        "    # for windows:\n",
        "    # audio_file = f\"/Users/mario/{audio_file[16:]}\".replace(\"\\\\\", \"/\")\n",
        "\n",
        "    # Zero-padding for an audio waveform with less than 5 seconds.\n",
        "    input_len = sr * 5\n",
        "    y = y[:input_len]\n",
        "    if (input_len > tf.shape(y)[0]):\n",
        "        zero_padding = tf.zeros(\n",
        "            [input_len] - tf.shape(y),\n",
        "            dtype=tf.float32)\n",
        "        y = tf.cast(y, dtype=tf.float32)\n",
        "        y = tf.concat([y, zero_padding], 0)\n",
        "    \n",
        "    return y, raw_df_soa.loc[audio_file][\"Emotion_Id\"]\n",
        "\n",
        "def data_loader(filename):\n",
        "    features, labels = tf.py_function(get_signal_and_label, [filename], [tf.float32, tf.int64])\n",
        "    return tf.reshape(features, [80000, 1]), tf.reshape(labels, [1])\n",
        "\n",
        "def preprocess_dataset(files):\n",
        "  # mac\n",
        "  filenames_ds = tf.data.Dataset.list_files([str(file) for file in files.index.values])\n",
        "  # windows\n",
        "  # filenames_ds = tf.data.Dataset.list_files([f\"C:\\\\Users\\\\Chico\\\\{str(file)[12:]}\" for file in files.index.values])\n",
        "\n",
        "  return filenames_ds.map(data_loader, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x864 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
        "\n",
        "for i, (audio, label) in enumerate(preprocess_dataset(raw_df_soa).take(9)):\n",
        "  r = i // 3\n",
        "  c = i % 3\n",
        "  ax = axes[r][c]\n",
        "  ax.plot(audio.numpy())\n",
        "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
        "  label = label.numpy()[0]\n",
        "  ax.set_title(label)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "____________________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   Trainable  \n",
            "============================================================================\n",
            " conv1d_7 (Conv1D)           (None, 79998, 128)        512       Y          \n",
            "                                                                            \n",
            " batch_normalization_7 (Batc  (None, 79998, 128)       512       Y          \n",
            " hNormalization)                                                            \n",
            "                                                                            \n",
            " activation_19 (Activation)  (None, 79998, 128)        0         Y          \n",
            "                                                                            \n",
            " max_pooling1d_6 (MaxPooling  (None, 19999, 128)       0         Y          \n",
            " 1D)                                                                        \n",
            "                                                                            \n",
            " dropout_12 (Dropout)        (None, 19999, 128)        0         Y          \n",
            "                                                                            \n",
            " flatten_6 (Flatten)         (None, 2559872)           0         Y          \n",
            "                                                                            \n",
            " dense_12 (Dense)            (None, 128)               32766374  Y          \n",
            "                                                       4                    \n",
            "                                                                            \n",
            " activation_20 (Activation)  (None, 128)               0         Y          \n",
            "                                                                            \n",
            " dropout_13 (Dropout)        (None, 128)               0         Y          \n",
            "                                                                            \n",
            " dense_13 (Dense)            (None, 4)                 516       Y          \n",
            "                                                                            \n",
            " activation_21 (Activation)  (None, 4)                 0         Y          \n",
            "                                                                            \n",
            "============================================================================\n",
            "Total params: 327,665,284\n",
            "Trainable params: 327,665,028\n",
            "Non-trainable params: 256\n",
            "____________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_model_1(input_shape=[80000, 1], activation = 'softmax', \n",
        "                  metrics = ['accuracy'], loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer=Adam(learning_rate=1e-5, epsilon=1e-6), n_labels = 4):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv1D(128, (3), input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(MaxPooling1D(n_labels))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(n_labels))\n",
        "\n",
        "    model.add(Activation(activation))\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "    return model\n",
        "build_model_1().summary(show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  4/461 [..............................] - ETA: 1:01:57 - loss: 2.9678 - accuracy: 0.2500"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb Cell 63'\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=55'>56</a>\u001b[0m verbosity \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=56'>57</a>\u001b[0m num_folds \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=58'>59</a>\u001b[0m categorical_cross_validation3(callback, no_epochs, batch_size, verbosity, num_folds)\n",
            "\u001b[1;32m/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb Cell 63'\u001b[0m in \u001b[0;36mcategorical_cross_validation3\u001b[0;34m(callback, no_epochs, batch_size, verbosity, num_folds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=21'>22</a>\u001b[0m test_ds \u001b[39m=\u001b[39m test_ds\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mprefetch(AUTOTUNE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining for fold \u001b[39m\u001b[39m{\u001b[39;00mfold_no\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=25'>26</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=26'>27</a>\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=27'>28</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49mno_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=28'>29</a>\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbosity,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=29'>30</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49m[callback],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=30'>31</a>\u001b[0m             workers\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=32'>33</a>\u001b[0m scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_ds, verbose\u001b[39m=\u001b[39mverbosity)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mario/Desktop/VADER/Audio_Sentiment_Analysis/iemocap/data/2_models_study.ipynb#ch0000061?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mScore for fold \u001b[39m\u001b[39m{\u001b[39;00mfold_no\u001b[39m}\u001b[39;00m\u001b[39m: Loss of \u001b[39m\u001b[39m{\u001b[39;00mscores[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m; Accuracy of \u001b[39m\u001b[39m{\u001b[39;00mscores[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def categorical_cross_validation3(callback, no_epochs, batch_size, verbosity, num_folds):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "  fold_no = 1\n",
        "  \n",
        "  X = raw_df_soa.iloc[:]\n",
        "  y = raw_df_soa.iloc[:,4:5]\n",
        "\n",
        "  for train, test in kfold.split(X, y):\n",
        "    model = build_model_1()\n",
        "    \n",
        "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
        "\n",
        "    train_ds = preprocess_dataset(X_train)\n",
        "    train_ds = train_ds.batch(8)\n",
        "    train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
        "\n",
        "    test_ds = preprocess_dataset(X_test)\n",
        "    test_ds = test_ds.batch(8)\n",
        "    test_ds = test_ds.cache().prefetch(AUTOTUNE)\n",
        "\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    history = model.fit(train_ds,\n",
        "                batch_size=batch_size,\n",
        "                epochs=no_epochs,\n",
        "                verbose=verbosity,\n",
        "                callbacks=[callback],\n",
        "                workers=8)\n",
        "\n",
        "    scores = model.evaluate(test_ds, verbose=verbosity)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: Loss of {scores[0]}; Accuracy of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Score per fold')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "\n",
        "no_epochs = 20\n",
        "batch_size = 16\n",
        "\n",
        "callback = EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "verbosity = 1\n",
        "num_folds = 3\n",
        "\n",
        "categorical_cross_validation3(callback, no_epochs, batch_size, verbosity, num_folds)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2_models_study.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
