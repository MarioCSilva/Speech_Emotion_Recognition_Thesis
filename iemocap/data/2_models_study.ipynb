{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# go to upper diretory\n",
    "sys.path.append(os.path.abspath('./../../../'))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest, RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, KFold\n",
    "from Audio_Sentiment_Analysis.utils.Configuration import Configuration\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "AUDIO_DIR = f\"{os.path.abspath('./../../../')}/IEMOCAP_Dataset\"\n",
    "EXTRACTED_FEATURES_FILE = 'extracted_features_iemocap.csv'\n",
    "CONFIG_FILE = f\"{os.path.abspath('./../../../')}/Audio_Sentiment_Analysis/iemocap/config.json\"\n",
    "config = Configuration.load_json(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the extracted features from the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Audio Files: 10039\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_Id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Dominance</th>\n",
       "      <th>std_chroma_stft</th>\n",
       "      <th>mean_zcr</th>\n",
       "      <th>...</th>\n",
       "      <th>max_mfcc6</th>\n",
       "      <th>min_mfcc7</th>\n",
       "      <th>var_mfcc9</th>\n",
       "      <th>max_mfcc9</th>\n",
       "      <th>max_mfcc10</th>\n",
       "      <th>max_mfcc13</th>\n",
       "      <th>var_mfcc14</th>\n",
       "      <th>var_mfcc15</th>\n",
       "      <th>min_mfcc17</th>\n",
       "      <th>min_mfcc19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro01_F012</th>\n",
       "      <td>improvised</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.750</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.296270</td>\n",
       "      <td>0.082856</td>\n",
       "      <td>...</td>\n",
       "      <td>39.327560</td>\n",
       "      <td>-40.651329</td>\n",
       "      <td>42.375973</td>\n",
       "      <td>19.492970</td>\n",
       "      <td>19.512123</td>\n",
       "      <td>18.821735</td>\n",
       "      <td>47.666279</td>\n",
       "      <td>51.472340</td>\n",
       "      <td>-18.892769</td>\n",
       "      <td>-27.943581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro04_F028</th>\n",
       "      <td>improvised</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.010</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.319851</td>\n",
       "      <td>0.086560</td>\n",
       "      <td>...</td>\n",
       "      <td>62.818893</td>\n",
       "      <td>-40.228039</td>\n",
       "      <td>84.092949</td>\n",
       "      <td>24.274593</td>\n",
       "      <td>11.059961</td>\n",
       "      <td>36.497154</td>\n",
       "      <td>29.247034</td>\n",
       "      <td>61.287384</td>\n",
       "      <td>-17.456673</td>\n",
       "      <td>-15.254041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro04_F029</th>\n",
       "      <td>improvised</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.160</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.298296</td>\n",
       "      <td>0.085880</td>\n",
       "      <td>...</td>\n",
       "      <td>29.858166</td>\n",
       "      <td>-33.455795</td>\n",
       "      <td>164.847565</td>\n",
       "      <td>34.833263</td>\n",
       "      <td>22.882631</td>\n",
       "      <td>33.635147</td>\n",
       "      <td>118.356186</td>\n",
       "      <td>128.460770</td>\n",
       "      <td>-32.842518</td>\n",
       "      <td>-12.516586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro04_F030</th>\n",
       "      <td>improvised</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.185</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.316109</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>...</td>\n",
       "      <td>48.537384</td>\n",
       "      <td>-38.774422</td>\n",
       "      <td>178.178299</td>\n",
       "      <td>24.138340</td>\n",
       "      <td>11.319570</td>\n",
       "      <td>35.046803</td>\n",
       "      <td>183.465393</td>\n",
       "      <td>119.128494</td>\n",
       "      <td>-13.127378</td>\n",
       "      <td>-24.713459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro04_F031</th>\n",
       "      <td>improvised</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.400</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.314387</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>...</td>\n",
       "      <td>44.125771</td>\n",
       "      <td>-49.090309</td>\n",
       "      <td>100.364433</td>\n",
       "      <td>35.686844</td>\n",
       "      <td>29.594337</td>\n",
       "      <td>11.990172</td>\n",
       "      <td>68.253944</td>\n",
       "      <td>51.992161</td>\n",
       "      <td>-20.573139</td>\n",
       "      <td>-20.019981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses05M_script03_2_M013</th>\n",
       "      <td>scripted</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.340</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.314951</td>\n",
       "      <td>0.063627</td>\n",
       "      <td>...</td>\n",
       "      <td>58.600712</td>\n",
       "      <td>-46.007534</td>\n",
       "      <td>113.818436</td>\n",
       "      <td>32.636822</td>\n",
       "      <td>28.463696</td>\n",
       "      <td>25.335880</td>\n",
       "      <td>78.160225</td>\n",
       "      <td>66.925186</td>\n",
       "      <td>-27.014687</td>\n",
       "      <td>-21.044426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses05M_script03_2_M014</th>\n",
       "      <td>scripted</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.150</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>0.067145</td>\n",
       "      <td>...</td>\n",
       "      <td>73.493271</td>\n",
       "      <td>-54.896301</td>\n",
       "      <td>162.575638</td>\n",
       "      <td>31.630028</td>\n",
       "      <td>12.225033</td>\n",
       "      <td>33.560890</td>\n",
       "      <td>87.977707</td>\n",
       "      <td>42.288971</td>\n",
       "      <td>-24.003210</td>\n",
       "      <td>-19.897762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses05M_script03_2_M018</th>\n",
       "      <td>scripted</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.170</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.302163</td>\n",
       "      <td>0.062219</td>\n",
       "      <td>...</td>\n",
       "      <td>51.708046</td>\n",
       "      <td>-34.321487</td>\n",
       "      <td>181.688660</td>\n",
       "      <td>23.869041</td>\n",
       "      <td>14.644627</td>\n",
       "      <td>14.957552</td>\n",
       "      <td>41.870499</td>\n",
       "      <td>43.103497</td>\n",
       "      <td>-20.033688</td>\n",
       "      <td>-19.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses05M_script03_2_M019</th>\n",
       "      <td>scripted</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.180</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.310805</td>\n",
       "      <td>0.116048</td>\n",
       "      <td>...</td>\n",
       "      <td>58.984211</td>\n",
       "      <td>-54.916523</td>\n",
       "      <td>73.387558</td>\n",
       "      <td>23.126339</td>\n",
       "      <td>13.553119</td>\n",
       "      <td>24.739117</td>\n",
       "      <td>51.918839</td>\n",
       "      <td>60.310535</td>\n",
       "      <td>-22.075874</td>\n",
       "      <td>-19.231363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses05M_script03_2_M021</th>\n",
       "      <td>scripted</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.400</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.320674</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>...</td>\n",
       "      <td>68.866486</td>\n",
       "      <td>-47.562469</td>\n",
       "      <td>194.224579</td>\n",
       "      <td>23.398148</td>\n",
       "      <td>23.116982</td>\n",
       "      <td>20.446377</td>\n",
       "      <td>71.395477</td>\n",
       "      <td>28.724272</td>\n",
       "      <td>-28.672276</td>\n",
       "      <td>-21.132488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10039 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Interaction  Gender  Duration Emotion  Emotion_Id  \\\n",
       "File                                                                       \n",
       "Ses01F_impro01_F012     improvised  Female     2.750   angry           0   \n",
       "Ses01F_impro04_F028     improvised  Female     2.010   angry           0   \n",
       "Ses01F_impro04_F029     improvised  Female     3.160   angry           0   \n",
       "Ses01F_impro04_F030     improvised  Female     3.185   angry           0   \n",
       "Ses01F_impro04_F031     improvised  Female     4.400   angry           0   \n",
       "...                            ...     ...       ...     ...         ...   \n",
       "Ses05M_script03_2_M013    scripted    Male     9.340   other          10   \n",
       "Ses05M_script03_2_M014    scripted    Male     4.150   other          10   \n",
       "Ses05M_script03_2_M018    scripted    Male     2.170   other          10   \n",
       "Ses05M_script03_2_M019    scripted    Male     1.180   other          10   \n",
       "Ses05M_script03_2_M021    scripted    Male     2.400   other          10   \n",
       "\n",
       "                        Valence  Activation  Dominance  std_chroma_stft  \\\n",
       "File                                                                      \n",
       "Ses01F_impro01_F012         2.0         3.5        3.5         0.296270   \n",
       "Ses01F_impro04_F028         2.0         3.5        3.5         0.319851   \n",
       "Ses01F_impro04_F029         1.5         4.0        4.0         0.298296   \n",
       "Ses01F_impro04_F030         1.5         3.5        4.0         0.316109   \n",
       "Ses01F_impro04_F031         1.5         3.0        3.5         0.314387   \n",
       "...                         ...         ...        ...              ...   \n",
       "Ses05M_script03_2_M013      2.0         3.5        4.0         0.314951   \n",
       "Ses05M_script03_2_M014      1.5         3.5        4.0         0.315053   \n",
       "Ses05M_script03_2_M018      3.5         3.0        3.0         0.302163   \n",
       "Ses05M_script03_2_M019      2.5         3.0        3.5         0.310805   \n",
       "Ses05M_script03_2_M021      2.0         3.5        4.0         0.320674   \n",
       "\n",
       "                        mean_zcr  ...  max_mfcc6  min_mfcc7   var_mfcc9  \\\n",
       "File                              ...                                     \n",
       "Ses01F_impro01_F012     0.082856  ...  39.327560 -40.651329   42.375973   \n",
       "Ses01F_impro04_F028     0.086560  ...  62.818893 -40.228039   84.092949   \n",
       "Ses01F_impro04_F029     0.085880  ...  29.858166 -33.455795  164.847565   \n",
       "Ses01F_impro04_F030     0.106300  ...  48.537384 -38.774422  178.178299   \n",
       "Ses01F_impro04_F031     0.065918  ...  44.125771 -49.090309  100.364433   \n",
       "...                          ...  ...        ...        ...         ...   \n",
       "Ses05M_script03_2_M013  0.063627  ...  58.600712 -46.007534  113.818436   \n",
       "Ses05M_script03_2_M014  0.067145  ...  73.493271 -54.896301  162.575638   \n",
       "Ses05M_script03_2_M018  0.062219  ...  51.708046 -34.321487  181.688660   \n",
       "Ses05M_script03_2_M019  0.116048  ...  58.984211 -54.916523   73.387558   \n",
       "Ses05M_script03_2_M021  0.120333  ...  68.866486 -47.562469  194.224579   \n",
       "\n",
       "                        max_mfcc9  max_mfcc10  max_mfcc13  var_mfcc14  \\\n",
       "File                                                                    \n",
       "Ses01F_impro01_F012     19.492970   19.512123   18.821735   47.666279   \n",
       "Ses01F_impro04_F028     24.274593   11.059961   36.497154   29.247034   \n",
       "Ses01F_impro04_F029     34.833263   22.882631   33.635147  118.356186   \n",
       "Ses01F_impro04_F030     24.138340   11.319570   35.046803  183.465393   \n",
       "Ses01F_impro04_F031     35.686844   29.594337   11.990172   68.253944   \n",
       "...                           ...         ...         ...         ...   \n",
       "Ses05M_script03_2_M013  32.636822   28.463696   25.335880   78.160225   \n",
       "Ses05M_script03_2_M014  31.630028   12.225033   33.560890   87.977707   \n",
       "Ses05M_script03_2_M018  23.869041   14.644627   14.957552   41.870499   \n",
       "Ses05M_script03_2_M019  23.126339   13.553119   24.739117   51.918839   \n",
       "Ses05M_script03_2_M021  23.398148   23.116982   20.446377   71.395477   \n",
       "\n",
       "                        var_mfcc15  min_mfcc17  min_mfcc19  \n",
       "File                                                        \n",
       "Ses01F_impro01_F012      51.472340  -18.892769  -27.943581  \n",
       "Ses01F_impro04_F028      61.287384  -17.456673  -15.254041  \n",
       "Ses01F_impro04_F029     128.460770  -32.842518  -12.516586  \n",
       "Ses01F_impro04_F030     119.128494  -13.127378  -24.713459  \n",
       "Ses01F_impro04_F031      51.992161  -20.573139  -20.019981  \n",
       "...                            ...         ...         ...  \n",
       "Ses05M_script03_2_M013   66.925186  -27.014687  -21.044426  \n",
       "Ses05M_script03_2_M014   42.288971  -24.003210  -19.897762  \n",
       "Ses05M_script03_2_M018   43.103497  -20.033688  -19.955128  \n",
       "Ses05M_script03_2_M019   60.310535  -22.075874  -19.231363  \n",
       "Ses05M_script03_2_M021   28.724272  -28.672276  -21.132488  \n",
       "\n",
       "[10039 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(EXTRACTED_FEATURES_FILE)\n",
    "print(f\"Number of Audio Files: {df.shape[0]}\")\n",
    "df = df.sort_values(['Emotion_Id', 'Gender'], ascending = (True, True))\n",
    "df = df.set_index('File')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used in SOA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <th>0</th>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <th>1</th>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <th>3</th>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Emotion\n",
       "                     count\n",
       "Emotion Emotion_Id        \n",
       "angry   0             1103\n",
       "happy   1             1636\n",
       "neutral 3             1708\n",
       "sad     2             1084"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soa = df[df['Emotion'].isin({'angry', 'neutral', 'sad', 'happy', 'excited'})]\n",
    "df_soa.loc[df_soa['Emotion'] == 'excited', 'Emotion'] = 'happy'\n",
    "df_soa.loc[df_soa['Emotion_Id'] == 5, 'Emotion_Id'] = 1\n",
    "df_soa.groupby(['Emotion', 'Emotion_Id']).agg({'Emotion': ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe improvised data is more adequate to the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion\n",
       "          count\n",
       "Emotion        \n",
       "angry       289\n",
       "happy       947\n",
       "neutral    1099\n",
       "sad         608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soa[df_soa['Interaction'] == 'improvised'].groupby(['Emotion']).agg({'Emotion': ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The duration of the audio can have importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion\n",
       "          count\n",
       "Emotion        \n",
       "angry       813\n",
       "happy      1170\n",
       "neutral    1105\n",
       "sad         843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soa[df_soa['Duration'] >= 2.5].groupby(['Emotion']).agg({'Emotion': ['count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm_predictions(model, input_data, labels, cv=5, draw_corr_matrix=True, verbose=1, n_jobs=4):\n",
    "    y_pred = cross_val_predict(model, input_data, labels, cv=cv, verbose=verbose, n_jobs=n_jobs)\n",
    "\n",
    "    print(\"accuracy: \", metrics.accuracy_score(labels, y_pred))\n",
    "    print(\"f1 score macro: \", metrics.f1_score(labels, y_pred, average='macro') )\n",
    "    print(\"f1 score micro: \", metrics.f1_score(labels, y_pred, average='micro') )\n",
    "    print(\"precision score: \", metrics.precision_score(labels, y_pred, average='macro') )\n",
    "    print(\"recall score: \", metrics.recall_score(labels, y_pred, average='macro') )\n",
    "    print(\"hamming loss: \", metrics.hamming_loss(labels, y_pred))\n",
    "    print(\"matthews corrcoef: \", metrics.matthews_corrcoef(labels, y_pred) )\n",
    "    print(\"zero one loss: \", metrics.zero_one_loss(labels, y_pred))\n",
    "    print(\"mean absolute error: \", metrics.mean_absolute_error(labels, y_pred))\n",
    "\n",
    "    print(metrics.classification_report(labels, y_pred))\n",
    "\n",
    "    if draw_corr_matrix:\n",
    "        cm = metrics.confusion_matrix(labels, y_pred)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.title(\"Confusion Matrix Predicted Labels\")\n",
    "        plt.xlabel(\"Emotions Labels\")\n",
    "        plt.ylabel(\"Emotions Labels\")\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_soa.iloc[:,8:]\n",
    "regression_labels = df_soa.iloc[:,5:8].values\n",
    "categorical_labels = np.ravel(df_soa.iloc[:,4:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Random Forests\n",
    "#### Categorical Problem (anger, happiness (+ excited), neutral, sadness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.4952088229976496\n",
      "f1 score macro:  0.5128402898669654\n",
      "f1 score micro:  0.4952088229976496\n",
      "precision score:  0.5235160408175284\n",
      "recall score:  0.5050289689027115\n",
      "hamming loss:  0.5047911770023504\n",
      "matthews corrcoef:  0.31341736401352394\n",
      "zero one loss:  0.5047911770023503\n",
      "mean absolute error:  0.7868378231784487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58      1103\n",
      "           1       0.41      0.45      0.42      1636\n",
      "           2       0.60      0.57      0.58      1084\n",
      "           3       0.45      0.47      0.46      1708\n",
      "\n",
      "    accuracy                           0.50      5531\n",
      "   macro avg       0.52      0.51      0.51      5531\n",
      "weighted avg       0.50      0.50      0.50      5531\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm_predictions(RandomForest(random_state=1, max_features=None), data.values, categorical_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Problem (Valence, Activation, Dominance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   5 | elapsed:   21.7s remaining:   32.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:   22.2s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=1, max_features=None)\n",
    "pred_values = cross_val_predict(model, data.values, regression_labels, cv=5, verbose=1, n_jobs=8)\n",
    "print('MAE: %.3f' % metrics.mean_absolute_error(pred_values, regression_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Networks\n",
    "#### Categorical Problem (anger, happiness (+ excited), neutral, sadness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 13:11:44.601607: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " conv1d (Conv1D)             (None, 20, 256)           1536      Y          \n",
      "                                                                            \n",
      " batch_normalization (BatchN  (None, 20, 256)          1024      Y          \n",
      " ormalization)                                                              \n",
      "                                                                            \n",
      " activation (Activation)     (None, 20, 256)           0         Y          \n",
      "                                                                            \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           163968    Y          \n",
      "                                                                            \n",
      " activation_1 (Activation)   (None, 16, 128)           0         Y          \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 16, 128)           0         Y          \n",
      "                                                                            \n",
      " max_pooling1d (MaxPooling1D  (None, 14, 128)          0         Y          \n",
      " )                                                                          \n",
      "                                                                            \n",
      " conv1d_2 (Conv1D)           (None, 10, 128)           82048     Y          \n",
      "                                                                            \n",
      " activation_2 (Activation)   (None, 10, 128)           0         Y          \n",
      "                                                                            \n",
      " batch_normalization_1 (Batc  (None, 10, 128)          512       Y          \n",
      " hNormalization)                                                            \n",
      "                                                                            \n",
      " dropout_1 (Dropout)         (None, 10, 128)           0         Y          \n",
      "                                                                            \n",
      " flatten (Flatten)           (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 3)                 3843      Y          \n",
      "                                                                            \n",
      " activation_3 (Activation)   (None, 3)                 0         Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 252,931\n",
      "Trainable params: 252,163\n",
      "Non-trainable params: 768\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model_0(input_shape=(24, 1), loss=MeanSquaredError(), optimizer=Adam(learning_rate=1e-5, epsilon=1e-6)):\n",
    "    if loss.__class__ == SparseCategoricalCrossentropy().__class__:\n",
    "        n_labels = 4\n",
    "        metrics = ['accuracy']\n",
    "        activation = 'softmax'\n",
    "    else:\n",
    "        n_labels = 3\n",
    "        metrics = ['mae']\n",
    "        activation = 'relu'\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, (5), input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv1D(128, (5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(n_labels, strides=1))\n",
    "\n",
    "    model.add(Conv1D(128, (5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(n_labels))\n",
    "\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "build_model_0(input_shape=(data.iloc[0].shape[0],1)).summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_validation(callbacks, no_epochs, batch_size, loss, optimizer, verbosity, num_folds):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
    "  acc_per_fold = []\n",
    "  loss_per_fold = []\n",
    "  fold_no = 1\n",
    "  \n",
    "  X = df_soa.iloc[:,8:]\n",
    "  y = df_soa.iloc[:,4:5]\n",
    "\n",
    "  for train, test in kfold.split(X, y):\n",
    "    model = build_model_0(input_shape=(data.shape[1], 1), loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=no_epochs,\n",
    "                verbose=verbosity,\n",
    "                callbacks=callbacks,\n",
    "                workers=4)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=verbosity)\n",
    "\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Score per fold')\n",
    "  for i in range(0, len(acc_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Average scores for all folds:')\n",
    "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "  print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Score for fold 1: loss of 1.111961007118225; accuracy of 49.232158064842224%\n",
      "Training for fold 2 ...\n",
      "Score for fold 2: loss of 1.1252243518829346; accuracy of 48.73417615890503%\n",
      "Training for fold 3 ...\n",
      "Score for fold 3: loss of 1.1336780786514282; accuracy of 46.473780274391174%\n",
      "Training for fold 4 ...\n",
      "Score for fold 4: loss of 1.1383367776870728; accuracy of 46.383363008499146%\n",
      "Training for fold 5 ...\n",
      "Score for fold 5: loss of 1.1080365180969238; accuracy of 48.19168150424957%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "> Fold 1 - Loss: 1.111961007118225 - Accuracy: 49.232158064842224%\n",
      "> Fold 2 - Loss: 1.1252243518829346 - Accuracy: 48.73417615890503%\n",
      "> Fold 3 - Loss: 1.1336780786514282 - Accuracy: 46.473780274391174%\n",
      "> Fold 4 - Loss: 1.1383367776870728 - Accuracy: 46.383363008499146%\n",
      "> Fold 5 - Loss: 1.1080365180969238 - Accuracy: 48.19168150424957%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 47.80303180217743 (+- 1.1698589134156916)\n",
      "> Loss: 1.123447346687317\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "no_epochs = 500 # try 300 or 700\n",
    "batch_size = 16 # try 16\n",
    "learning_rate=1e-5 # try 1e-4\n",
    "loss = SparseCategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "verbosity = 0\n",
    "num_folds = 5\n",
    "\n",
    "categorical_cross_validation(callback, no_epochs, batch_size, loss, optimizer, verbosity, num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Problem (Valence, Activation, Dominance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here Stratified K-Fold cannot be used because it has a continuous multi output label, so the distribution of emotions per fold is not going to be balanced.\n",
    "\n",
    "Could use the categorical emotion to generate the folds and then use the regression labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_cross_validation(callbacks, no_epochs, batch_size, loss, optimizer, verbosity, num_folds):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  kfold = KFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
    "  mae_per_fold = []\n",
    "  loss_per_fold = []\n",
    "  fold_no = 1\n",
    "  \n",
    "  X = df_soa.iloc[:,8:]\n",
    "  y = df_soa.iloc[:,5:8]\n",
    "\n",
    "  for train, test in kfold.split(X, y):\n",
    "    model = build_model_0(input_shape=(data.shape[1], 1), loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=no_epochs,\n",
    "                verbose=verbosity,\n",
    "                callbacks=callbacks,\n",
    "                workers=4)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=verbosity)\n",
    "\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    mae_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Score per fold')\n",
    "  for i in range(0, len(mae_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - MAE: {mae_per_fold[i]}%')\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Average scores for all folds:')\n",
    "  print(f'> MAE: {np.mean(mae_per_fold)} (+- {np.std(mae_per_fold)})')\n",
    "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "  print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Score for fold 1: loss of 0.5870349407196045; mae of 58.70349407196045%\n",
      "Training for fold 2 ...\n",
      "Score for fold 2: loss of 0.615779459476471; mae of 61.577945947647095%\n",
      "Training for fold 3 ...\n",
      "Score for fold 3: loss of 0.5887221693992615; mae of 58.87221693992615%\n",
      "Training for fold 4 ...\n",
      "Score for fold 4: loss of 0.5906510353088379; mae of 59.06510353088379%\n",
      "Training for fold 5 ...\n",
      "Score for fold 5: loss of 0.6135765910148621; mae of 61.35765314102173%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "> Fold 1 - Loss: 0.5870349407196045 - MAE: 58.70349407196045%\n",
      "> Fold 2 - Loss: 0.615779459476471 - MAE: 61.577945947647095%\n",
      "> Fold 3 - Loss: 0.5887221693992615 - MAE: 58.87221693992615%\n",
      "> Fold 4 - Loss: 0.5906510353088379 - MAE: 59.06510353088379%\n",
      "> Fold 5 - Loss: 0.6135765910148621 - MAE: 61.35765314102173%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> MAE: 59.91528272628784 (+- 1.2746845917867797)\n",
      "> Loss: 0.5991528391838074\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "no_epochs = 500 # try 300 or 700\n",
    "batch_size = 32 # try 16\n",
    "learning_rate=1e-5 # try 1e-5\n",
    "loss = MeanAbsoluteError()\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "verbosity = 0\n",
    "num_folds = 5\n",
    "\n",
    "regression_cross_validation(callback, no_epochs, batch_size, loss, optimizer, verbosity, num_folds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
