\section{Classifiers Results and Discussion}

In this section, we present and analyze the results of the best candidate models obtained from both the traditional and deep learning approaches.

The top-performing model from the traditional approach is an AdaBoost classifier with a Random Forest base estimator, utilizing 33 audio features as input. This model achieved an accuracy of 60.04\% after performing 5-fold cross-validation on the \ac{iemo} dataset.

On the other hand, the final model obtained from the deep learning approach is a Resnet50 model, which uses Spectrogram images as input. This model achieved an accuracy of 58.24\%.

Table \ref{final_models} shows the performance of final models that were trained using the entire \ac{iemo} dataset and then tested on three different datasets, namely eNTERFACE'05, EMO-DB, and CREMA-D.

The traditional model achieved the highest accuracy on the CREMA-D dataset with 48.88\%, followed by the eNTERFACE'05 dataset with 46.03\%, and the EMO-DB dataset with 38.94\%. On the other hand, the deep learning model achieved the highest precision on the eNTERFACE'05 dataset with 52.13\%, followed by the CREMA-D dataset with 34.91\%, and the EMO-DB dataset with 12.78\%. However, the traditional model outperformed the deep learning model on all other metrics, including macro F1, recall, and \ac{mcc}.

In terms of computation time, the traditional models were faster than the deep learning models, which is evident from the lower time values in the table. This is a crucial factor when employing these models for real-time emotion recognition systems.

Moreover, in figure \ref{fig:final_cm} it is possible to observe that the final models output "angry" several times indicating that it has difficulty distinguishing anger and happiness on these datasets. It was also noted from the EMO-DB confusion matrix, that the language of the data used is a limitation of the models' capacity, as this dataset's audio files are spoken in German. This highlights the English language bias of our \ac{ser} models and suggests that the results for other spoken languages may not be satisfactory.

Overall, these results indicate that the Deep Learning model might be more effective for the \ac{ser} task on different datasets, due to its effective feature extraction and generalization capabilities. However, it is slower than the traditional models which can have a big impact when applied to real-time systems. We also recommend to use these models for English audios, reducing the potential error caused by the language bias, since the results on a German dataset, EMO-DB, and on a dataset with varied accents, eNTERFACE'05 the results are not as good. It is also essential to acknowledge that the deep learning models can yield even better results with a deeper hyperparameter tuning, which demands more computation time and power for their proper  development and evaluation.


\begin{table}[H]
	\centering
	\caption{Final models trained on \ac{iemo} and evaluated on different datasets.}
	\label{final_models}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{llrrrrrr}
			\toprule
			Dataset & Model & Accuracy & Macro F1 & Precision & Recall & \ac{mcc} & Time \\
			\midrule
			
			eNTERFACE'05 & Traditional & 29.37 & 18.61 & 17.85 & 22.02 & 0.064 & 0.18 \\
			 & Deep Learning & 36.67 & 22.91 & 44.36 & 27.50 & 0.087 & 0.25 \\

			\addlinespace
			
			EMO-DB & Traditional & 38.94 & 17.36 & 25.75 & 26.72 & 0.087 & 0.11 \\
			 & Deep Learning & 38.35 & 15.79 & 37.78 & 25.99 & 0.066 & 0.18 \\ 
			 			 
			 \addlinespace
			 CREMA-D & Traditional & 44.41 & 35.45 & 63.18 & 46.12 & 0.335 &  0.11 \\
			 & Deep Learning & 54.14 & 47.71 & 51.68 & 52.98 & 0.407 & 0.30 \\
			 
			\bottomrule
		\end{tabular}%
	}
\end{table}


\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figs/4_5_discussion/ent_trad_cm.png}
		\caption{eNTERFACE'05 Traditional Model Confusion Matrix.}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figs/4_5_discussion/ent_deep_cm.png}
		\caption{eNTERFACE'05 \ac{dl} Model Confusion Matrix.}
	\end{subfigure}
	\newline
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figs/4_5_discussion/emo_trad_cm.png}
		\caption{EMO-DB Traditional Model Confusion Matrix.}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figs/4_5_discussion/emo_deep_cm.png}
		\caption{EMO-DB \ac{dl} Model Confusion Matrix.}
	\end{subfigure}
	\newline
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figs/4_5_discussion/cre_trad_cm.png}
		\caption{CREMA-D Traditional Model Confusion Matrix.}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figs/4_5_discussion/cre_deep_cm.png}
		\caption{CREMA-D \ac{dl} Model Confusion Matrix.}
	\end{subfigure}
	\caption{Final Models Confusion Matrices on the eNTERFACE'05, EMO-DB and CREMA-D Datasets.}
	\label{fig:final_cm}
\end{figure}

